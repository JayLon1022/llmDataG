{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入原始数据集\n",
    "import pandas as pd\n",
    "test_data = pd.read_csv(\"UNSW_NB15_Mul/UNSW_NB15_testing-set.csv\")\n",
    "train_data = pd.read_csv(\"UNSW_NB15_Mul/UNSW_NB15_training-set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始数据集处理\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train_data['proto'] = label_encoder.fit_transform(train_data['proto'])\n",
    "test_data['proto'] = label_encoder.fit_transform(test_data['proto'])\n",
    "train_data['service'] = label_encoder.fit_transform(train_data['service'])\n",
    "test_data['service'] = label_encoder.fit_transform(test_data['service'])\n",
    "train_data['state'] = label_encoder.fit_transform(train_data['state'])\n",
    "test_data['state'] = label_encoder.fit_transform(test_data['state'])\n",
    "\n",
    "# 保存修改后的数据\n",
    "train_data.to_csv(\"UNSW_NB15_Mul/train_data.csv\",index=False)\n",
    "test_data.to_csv(\"UNSW_NB15_Mul/test_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_self:\n",
      "56000\n",
      "test_self:\n",
      "37000\n"
     ]
    }
   ],
   "source": [
    "# 处理自体数据\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "test_self = test_data[test_data['label'] == 0].drop(['label', 'id','attack_cat'], axis=1)\n",
    "train_self = train_data[train_data['label'] == 0].drop(['label', 'id','attack_cat'], axis=1)\n",
    "\n",
    "train_self = pd.DataFrame(scaler.fit_transform(train_self).round(5))\n",
    "test_self = pd.DataFrame(scaler.fit_transform(test_self).round(5))\n",
    "print('train_self:')\n",
    "print(len(train_self))\n",
    "print('test_self:')\n",
    "print(len(test_self))\n",
    "test_self.to_csv(\"self/test_self.csv\",index=False)\n",
    "train_self.to_csv(\"self/train_self.csv\",index=False)\n",
    "\n",
    "# 存储训练自体数据\n",
    "train_self_20 =  train_self.sample(n=5000, random_state=42) # 采样1170\n",
    "train_self_20.to_csv(\"train_self.csv\",index = False)\n",
    "test_self_20 = test_self.sample(n=5000 , random_state=42)\n",
    "test_self_20.to_csv(\"test_self.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_Total: 45332\n",
      "test_Analysis: 677 (1.49%)\n",
      "test_Backdoor: 583 (1.29%)\n",
      "test_DoS: 4089 (9.02%)\n",
      "test_Exploits: 11132 (24.56%)\n",
      "test_Fuzzers: 6062 (13.37%)\n",
      "test_Generic: 18871 (41.63%)\n",
      "test_Reconnaissance: 3496 (7.71%)\n",
      "test_Shellcode: 378 (0.83%)\n",
      "test_Worms: 44 (0.10%)\n",
      "\n",
      "\n",
      "train_Total: 119341\n",
      "train_Analysis: 2000 (1.68%)\n",
      "train_Backdoor: 1746 (1.46%)\n",
      "train_DoS: 12264 (10.28%)\n",
      "train_Exploits: 33393 (27.98%)\n",
      "train_Fuzzers: 18184 (15.24%)\n",
      "train_Generic: 40000 (33.52%)\n",
      "train_Reconnaissance: 10491 (8.79%)\n",
      "train_Shellcode: 1133 (0.95%)\n",
      "train_Worms: 130 (0.11%)\n"
     ]
    }
   ],
   "source": [
    "# 处理非自体数据\n",
    "test_nonself = test_data[test_data['label'] == 1].drop(['label', 'id','attack_cat'], axis=1)\n",
    "train_nonself = train_data[train_data['label'] == 1].drop(['label', 'id','attack_cat'], axis=1)\n",
    "train_nonself = pd.DataFrame(scaler.fit_transform(train_nonself).round(5))\n",
    "test_nonself = pd.DataFrame(scaler.fit_transform(test_nonself).round(5))\n",
    "\n",
    "test_nonself.to_csv(\"nonself/test_nonself.csv\",index=False)\n",
    "train_nonself.to_csv(\"nonself/train_nonself.csv\",index=False)\n",
    "\n",
    "\n",
    "# 测试集数据攻击分类\n",
    "test_Analysis = test_data[test_data['attack_cat'] == 'Analysis'].drop(['label', 'id', 'attack_cat'], axis=1)\n",
    "test_Analysis = pd.DataFrame(scaler.fit_transform(test_Analysis).round(5))\n",
    "\n",
    "test_Backdoor = test_data[test_data['attack_cat'] == 'Backdoor'].drop(['label', 'id', 'attack_cat'], axis=1) \n",
    "test_Backdoor = pd.DataFrame(scaler.fit_transform(test_Backdoor).round(5))\n",
    "\n",
    "test_DoS = test_data[test_data['attack_cat'] == 'DoS'].drop(['label', 'id', 'attack_cat'], axis=1)  \n",
    "test_DoS = pd.DataFrame(scaler.fit_transform(test_DoS).round(5))\n",
    "\n",
    "test_Exploits = test_data[test_data['attack_cat'] == 'Exploits'].drop(['label', 'id', 'attack_cat'], axis=1)\n",
    "test_Exploits = pd.DataFrame(scaler.fit_transform(test_Exploits).round(5))\n",
    "\n",
    "test_Fuzzers = test_data[test_data['attack_cat'] == 'Fuzzers'].drop(['label', 'id', 'attack_cat'], axis=1)\n",
    "test_Fuzzers = pd.DataFrame(scaler.fit_transform(test_Fuzzers).round(5))\n",
    "\n",
    "test_Generic = test_data[test_data['attack_cat'] == 'Generic'].drop(['label', 'id', 'attack_cat'], axis=1)\n",
    "test_Generic = pd.DataFrame(scaler.fit_transform(test_Generic).round(5))\n",
    "\n",
    "test_Reconnaissance = test_data[test_data['attack_cat'] == 'Reconnaissance'].drop(['label', 'id', 'attack_cat'], axis=1)\n",
    "test_Reconnaissance = pd.DataFrame(scaler.fit_transform(test_Reconnaissance).round(5))\n",
    "\n",
    "test_Shellcode = test_data[test_data['attack_cat'] == 'Shellcode'].drop(['label', 'id', 'attack_cat'], axis=1)\n",
    "test_Shellcode = pd.DataFrame(scaler.fit_transform(test_Shellcode).round(5))\n",
    "\n",
    "test_Worms = test_data[test_data['attack_cat'] == 'Worms'].drop(['label', 'id', 'attack_cat'], axis=1)\n",
    "test_Worms = pd.DataFrame(scaler.fit_transform(test_Worms).round(5))\n",
    "\n",
    "total_len = len(test_nonself)\n",
    "\n",
    "# 打印每一类长度和比例\n",
    "print(f\"test_Total: {len(test_nonself)}\")\n",
    "print(f\"test_Analysis: {len(test_Analysis)} ({len(test_Analysis) / total_len:.2%})\")\n",
    "print(f\"test_Backdoor: {len(test_Backdoor)} ({len(test_Backdoor) / total_len:.2%})\")\n",
    "print(f\"test_DoS: {len(test_DoS)} ({len(test_DoS) / total_len:.2%})\")\n",
    "print(f\"test_Exploits: {len(test_Exploits)} ({len(test_Exploits) / total_len:.2%})\")\n",
    "print(f\"test_Fuzzers: {len(test_Fuzzers)} ({len(test_Fuzzers) / total_len:.2%})\")\n",
    "print(f\"test_Generic: {len(test_Generic)} ({len(test_Generic) / total_len:.2%})\")\n",
    "print(f\"test_Reconnaissance: {len(test_Reconnaissance)} ({len(test_Reconnaissance) / total_len:.2%})\")\n",
    "print(f\"test_Shellcode: {len(test_Shellcode)} ({len(test_Shellcode) / total_len:.2%})\")\n",
    "print(f\"test_Worms: {len(test_Worms)} ({len(test_Worms) / total_len:.2%})\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# 训练集数据攻击分类\n",
    "train_Analysis = train_data[train_data['attack_cat'] == 'Analysis'].drop(['label', 'id', 'attack_cat'], axis=1)\n",
    "train_Analysis = pd.DataFrame(scaler.fit_transform(train_Analysis).round(5))\n",
    "\n",
    "train_Backdoor = train_data[train_data['attack_cat'] == 'Backdoor'].drop(['label', 'id', 'attack_cat'], axis=1) \n",
    "train_Backdoor = pd.DataFrame(scaler.fit_transform(train_Backdoor).round(5))\n",
    "\n",
    "train_DoS = train_data[train_data['attack_cat'] == 'DoS'].drop(['label', 'id', 'attack_cat'], axis=1)  \n",
    "train_DoS = pd.DataFrame(scaler.fit_transform(train_DoS).round(5))\n",
    "\n",
    "train_Exploits = train_data[train_data['attack_cat'] == 'Exploits'].drop(['label', 'id', 'attack_cat'], axis=1)\n",
    "train_Exploits = pd.DataFrame(scaler.fit_transform(train_Exploits).round(5))\n",
    "\n",
    "train_Fuzzers = train_data[train_data['attack_cat'] == 'Fuzzers'].drop(['label', 'id', 'attack_cat'], axis=1)\n",
    "train_Fuzzers = pd.DataFrame(scaler.fit_transform(train_Fuzzers).round(5))\n",
    "\n",
    "train_Generic = train_data[train_data['attack_cat'] == 'Generic'].drop(['label', 'id', 'attack_cat'], axis=1)\n",
    "train_Generic = pd.DataFrame(scaler.fit_transform(train_Generic).round(5))\n",
    "\n",
    "train_Reconnaissance = train_data[train_data['attack_cat'] == 'Reconnaissance'].drop(['label', 'id', 'attack_cat'], axis=1)\n",
    "train_Reconnaissance = pd.DataFrame(scaler.fit_transform(train_Reconnaissance).round(5))\n",
    "\n",
    "train_Shellcode = train_data[train_data['attack_cat'] == 'Shellcode'].drop(['label', 'id', 'attack_cat'], axis=1)\n",
    "train_Shellcode = pd.DataFrame(scaler.fit_transform(train_Shellcode).round(5))\n",
    "\n",
    "train_Worms = train_data[train_data['attack_cat'] == 'Worms'].drop(['label', 'id', 'attack_cat'], axis=1)\n",
    "train_Worms = pd.DataFrame(scaler.fit_transform(train_Worms).round(5))\n",
    "\n",
    "total_len = len(train_nonself)\n",
    "\n",
    "# 打印每一类长度和比例\n",
    "print(f\"train_Total: {len(train_nonself)}\")\n",
    "print(f\"train_Analysis: {len(train_Analysis)} ({len(train_Analysis) / total_len:.2%})\")\n",
    "print(f\"train_Backdoor: {len(train_Backdoor)} ({len(train_Backdoor) / total_len:.2%})\")\n",
    "print(f\"train_DoS: {len(train_DoS)} ({len(train_DoS) / total_len:.2%})\")\n",
    "print(f\"train_Exploits: {len(train_Exploits)} ({len(train_Exploits) / total_len:.2%})\")\n",
    "print(f\"train_Fuzzers: {len(train_Fuzzers)} ({len(train_Fuzzers) / total_len:.2%})\")\n",
    "print(f\"train_Generic: {len(train_Generic)} ({len(train_Generic) / total_len:.2%})\")\n",
    "print(f\"train_Reconnaissance: {len(train_Reconnaissance)} ({len(train_Reconnaissance) / total_len:.2%})\")\n",
    "print(f\"train_Shellcode: {len(train_Shellcode)} ({len(train_Shellcode) / total_len:.2%})\")\n",
    "print(f\"train_Worms: {len(train_Worms)} ({len(train_Worms) / total_len:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存每个类别的非自体数据到指定路径\n",
    "\n",
    "train_Analysis.to_csv(\"test_20/check/nonself/train/trainA.csv\", index=False)\n",
    "train_Backdoor.to_csv(\"test_20/check/nonself/train/trainB.csv\", index=False)\n",
    "train_DoS.to_csv(\"test_20/check/nonself/train/trainD.csv\", index=False)\n",
    "train_Exploits.to_csv(\"test_20/check/nonself/train/trainE.csv\", index=False)\n",
    "train_Fuzzers.to_csv(\"test_20/check/nonself/train/trainF.csv\", index=False)\n",
    "train_Generic.to_csv(\"test_20/check/nonself/train/trainG.csv\", index=False)\n",
    "train_Reconnaissance.to_csv(\"test_20/check/nonself/train/trainR.csv\", index=False)\n",
    "train_Shellcode.to_csv(\"test_20/check/nonself/train/trainS.csv\", index=False)\n",
    "train_Worms.to_csv(\"test_20/check/nonself/train/trainW.csv\", index=False)\n",
    "\n",
    "\n",
    "test_Analysis.to_csv(\"test_20/check/nonself/test/testA.csv\", index=False)\n",
    "test_Backdoor.to_csv(\"test_20/check/nonself/test/testB.csv\", index=False)\n",
    "test_DoS.to_csv(\"test_20/check/nonself/test/testD.csv\", index=False)\n",
    "test_Exploits.to_csv(\"test_20/check/nonself/test/testE.csv\", index=False)\n",
    "test_Fuzzers.to_csv(\"test_20/check/nonself/test/testF.csv\", index=False)\n",
    "test_Generic.to_csv(\"test_20/check/nonself/test/testG.csv\", index=False)\n",
    "test_Reconnaissance.to_csv(\"test_20/check/nonself/test/testR.csv\", index=False)\n",
    "test_Shellcode.to_csv(\"test_20/check/nonself/test/testS.csv\", index=False)\n",
    "test_Worms.to_csv(\"test_20/check/nonself/test/testW.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集采样\n",
    "\n",
    "trainset_Analysis_sampled = train_Analysis.sample(n=130, random_state=42)\n",
    "trainset_Backdoor_sampled = train_Backdoor.sample(n=130, random_state=42)\n",
    "trainset_DoS_sampled = train_DoS.sample(n=130, random_state=42)\n",
    "trainset_Exploits_sampled = train_Exploits.sample(n=130, random_state=42)\n",
    "trainset_Fuzzers_sampled = train_Fuzzers.sample(n=130, random_state=42)\n",
    "trainset_Generic_sampled = train_Generic.sample(n=130, random_state=42)\n",
    "trainset_Reconnaissance_sampled = train_Reconnaissance.sample(n=130, random_state=42)\n",
    "trainset_Shellcode_sampled = train_Shellcode.sample(n=130, random_state=42)\n",
    "trainset_Worms_sampled = train_Worms.sample(n=130, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "round = '8'\n",
    "rs = 742\n",
    "train_Analysis_sampled = trainset_Analysis_sampled.sample(n=20, random_state=rs)\n",
    "train_Backdoor_sampled = trainset_Backdoor_sampled.sample(n=20, random_state=rs)\n",
    "train_DoS_sampled = trainset_DoS_sampled.sample(n=20, random_state=rs)\n",
    "train_Exploits_sampled = trainset_Exploits_sampled.sample(n=20, random_state=rs)\n",
    "train_Fuzzers_sampled = trainset_Fuzzers_sampled.sample(n=20, random_state=rs)\n",
    "train_Generic_sampled = trainset_Generic_sampled.sample(n=20, random_state=rs)\n",
    "train_Reconnaissance_sampled = trainset_Reconnaissance_sampled.sample(n=20, random_state=rs)\n",
    "train_Shellcode_sampled = trainset_Shellcode_sampled.sample(n=20, random_state=rs)\n",
    "train_Worms_sampled = trainset_Worms_sampled.sample(n=20, random_state=rs)\n",
    "# 生成实验数据\n",
    "\n",
    "# 无Analysis\n",
    "trainA_nonself = pd.concat([train_Backdoor_sampled, train_DoS_sampled,\n",
    "                          train_Exploits_sampled, train_Fuzzers_sampled, train_Generic_sampled,\n",
    "                          train_Reconnaissance_sampled, train_Shellcode_sampled, train_Worms_sampled],\n",
    "                         axis=0)\n",
    "trainA_nonself.to_csv(f\"A/Round{round}/trainA_nonself.csv\", index=False)\n",
    "\n",
    "# 无Backdoor\n",
    "trainB_nonself = pd.concat([train_Analysis_sampled, train_DoS_sampled,\n",
    "                          train_Exploits_sampled, train_Fuzzers_sampled, train_Generic_sampled,\n",
    "                          train_Reconnaissance_sampled, train_Shellcode_sampled, train_Worms_sampled],\n",
    "                         axis=0)\n",
    "trainB_nonself.to_csv(f\"B/Round{round}/trainB_nonself.csv\", index=False)\n",
    "\n",
    "# 无DoS\n",
    "trainD_nonself = pd.concat([train_Analysis_sampled, train_Backdoor_sampled,\n",
    "                          train_Exploits_sampled, train_Fuzzers_sampled, train_Generic_sampled,\n",
    "                          train_Reconnaissance_sampled, train_Shellcode_sampled, train_Worms_sampled],\n",
    "                         axis=0)\n",
    "trainD_nonself.to_csv(f\"D/Round{round}/trainD_nonself.csv\", index=False)\n",
    "\n",
    "# 无Exploits\n",
    "trainE_nonself = pd.concat([train_Analysis_sampled, train_Backdoor_sampled, train_DoS_sampled,\n",
    "                           train_Fuzzers_sampled, train_Generic_sampled,\n",
    "                          train_Reconnaissance_sampled, train_Shellcode_sampled, train_Worms_sampled],\n",
    "                         axis=0)\n",
    "trainE_nonself.to_csv(f\"E/Round{round}/trainE_nonself.csv\", index=False)\n",
    "\n",
    "# 无Fuzzers\n",
    "trainF_nonself = pd.concat([train_Analysis_sampled, train_Backdoor_sampled, train_DoS_sampled,\n",
    "                          train_Exploits_sampled, train_Generic_sampled,\n",
    "                          train_Reconnaissance_sampled, train_Shellcode_sampled, train_Worms_sampled],\n",
    "                         axis=0)\n",
    "trainF_nonself.to_csv(f\"F/Round{round}/trainF_nonself.csv\", index=False)\n",
    "\n",
    "# 无Generic\n",
    "trainG_nonself = pd.concat([train_Analysis_sampled, train_Backdoor_sampled, train_DoS_sampled,\n",
    "                          train_Exploits_sampled, train_Fuzzers_sampled,\n",
    "                          train_Reconnaissance_sampled, train_Shellcode_sampled, train_Worms_sampled],\n",
    "                         axis=0)\n",
    "trainG_nonself.to_csv(f\"G/Round{round}/trainG_nonself.csv\", index=False)\n",
    "\n",
    "# 无Reconnaissance\n",
    "trainR_nonself = pd.concat([train_Analysis_sampled, train_Backdoor_sampled, train_DoS_sampled,\n",
    "                          train_Exploits_sampled, train_Fuzzers_sampled, train_Generic_sampled,\n",
    "                          train_Shellcode_sampled, train_Worms_sampled],\n",
    "                         axis=0)\n",
    "trainR_nonself.to_csv(f\"R/Round{round}/trainR_nonself.csv\", index=False)\n",
    "\n",
    "# 无Shellcode\n",
    "trainS_nonself = pd.concat([train_Analysis_sampled, train_Backdoor_sampled, train_DoS_sampled,\n",
    "                          train_Exploits_sampled, train_Fuzzers_sampled, train_Generic_sampled,\n",
    "                          train_Reconnaissance_sampled, train_Worms_sampled],\n",
    "                         axis=0)\n",
    "trainS_nonself.to_csv(f\"S/Round{round}/trainS_nonself.csv\", index=False)\n",
    "\n",
    "# 无Worms\n",
    "trainW_nonself = pd.concat([train_Analysis_sampled, train_Backdoor_sampled, train_DoS_sampled,\n",
    "                          train_Exploits_sampled, train_Fuzzers_sampled, train_Generic_sampled,\n",
    "                          train_Reconnaissance_sampled, train_Shellcode_sampled],\n",
    "                         axis=0)\n",
    "trainW_nonself.to_csv(f\"W/Round{round}/trainW_nonself.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实验数据采样\n",
    "\n",
    "train_Analysis_sampled = train_Analysis.sample(n=20, random_state=42)\n",
    "train_Backdoor_sampled = train_Backdoor.sample(n=20, random_state=42)\n",
    "train_DoS_sampled = train_DoS.sample(n=20, random_state=42)\n",
    "train_Exploits_sampled = train_Exploits.sample(n=20, random_state=42)\n",
    "train_Fuzzers_sampled = train_Fuzzers.sample(n=20, random_state=42)\n",
    "train_Generic_sampled = train_Generic.sample(n=20, random_state=42)\n",
    "train_Reconnaissance_sampled = train_Reconnaissance.sample(n=20, random_state=42)\n",
    "train_Shellcode_sampled = train_Shellcode.sample(n=20, random_state=42)\n",
    "train_Worms_sampled = train_Worms.sample(n=20, random_state=42)\n",
    "\n",
    "# 生成实验数据\n",
    "\n",
    "# 无Analysis\n",
    "trainA_nonself = pd.concat([train_Backdoor_sampled, train_DoS_sampled,\n",
    "                          train_Exploits_sampled, train_Fuzzers_sampled, train_Generic_sampled,\n",
    "                          train_Reconnaissance_sampled, train_Shellcode_sampled, train_Worms_sampled],\n",
    "                         axis=0)\n",
    "trainA_nonself.to_csv(\"test_20/seed/trainA_nonself.csv\", index=False)\n",
    "\n",
    "# 无Backdoor\n",
    "trainB_nonself = pd.concat([train_Analysis_sampled, train_DoS_sampled,\n",
    "                          train_Exploits_sampled, train_Fuzzers_sampled, train_Generic_sampled,\n",
    "                          train_Reconnaissance_sampled, train_Shellcode_sampled, train_Worms_sampled],\n",
    "                         axis=0)\n",
    "trainB_nonself.to_csv(\"test_20/seed/trainB_nonself.csv\", index=False)\n",
    "\n",
    "# 无DoS\n",
    "trainD_nonself = pd.concat([train_Analysis_sampled, train_Backdoor_sampled,\n",
    "                          train_Exploits_sampled, train_Fuzzers_sampled, train_Generic_sampled,\n",
    "                          train_Reconnaissance_sampled, train_Shellcode_sampled, train_Worms_sampled],\n",
    "                         axis=0)\n",
    "trainD_nonself.to_csv(\"test_20/seed/trainD_nonself.csv\", index=False)\n",
    "\n",
    "# 无Exploits\n",
    "trainE_nonself = pd.concat([train_Analysis_sampled, train_Backdoor_sampled, train_DoS_sampled,\n",
    "                           train_Fuzzers_sampled, train_Generic_sampled,\n",
    "                          train_Reconnaissance_sampled, train_Shellcode_sampled, train_Worms_sampled],\n",
    "                         axis=0)\n",
    "trainE_nonself.to_csv(\"test_20/seed/trainE_nonself.csv\", index=False)\n",
    "\n",
    "# 无Fuzzers\n",
    "trainF_nonself = pd.concat([train_Analysis_sampled, train_Backdoor_sampled, train_DoS_sampled,\n",
    "                          train_Exploits_sampled, train_Generic_sampled,\n",
    "                          train_Reconnaissance_sampled, train_Shellcode_sampled, train_Worms_sampled],\n",
    "                         axis=0)\n",
    "trainF_nonself.to_csv(\"test_20/seed/trainF_nonself.csv\", index=False)\n",
    "\n",
    "# 无Generic\n",
    "trainG_nonself = pd.concat([train_Analysis_sampled, train_Backdoor_sampled, train_DoS_sampled,\n",
    "                          train_Exploits_sampled, train_Fuzzers_sampled,\n",
    "                          train_Reconnaissance_sampled, train_Shellcode_sampled, train_Worms_sampled],\n",
    "                         axis=0)\n",
    "trainG_nonself.to_csv(\"test_20/seed/trainG_nonself.csv\", index=False)\n",
    "\n",
    "# 无Reconnaissance\n",
    "trainR_nonself = pd.concat([train_Analysis_sampled, train_Backdoor_sampled, train_DoS_sampled,\n",
    "                          train_Exploits_sampled, train_Fuzzers_sampled, train_Generic_sampled,\n",
    "                          train_Shellcode_sampled, train_Worms_sampled],\n",
    "                         axis=0)\n",
    "trainR_nonself.to_csv(\"test_20/seed/trainR_nonself.csv\", index=False)\n",
    "\n",
    "# 无Shellcode\n",
    "trainS_nonself = pd.concat([train_Analysis_sampled, train_Backdoor_sampled, train_DoS_sampled,\n",
    "                          train_Exploits_sampled, train_Fuzzers_sampled, train_Generic_sampled,\n",
    "                          train_Reconnaissance_sampled, train_Worms_sampled],\n",
    "                         axis=0)\n",
    "trainS_nonself.to_csv(\"test_20/seed/trainS_nonself.csv\", index=False)\n",
    "\n",
    "# 无Worms\n",
    "trainW_nonself = pd.concat([train_Analysis_sampled, train_Backdoor_sampled, train_DoS_sampled,\n",
    "                          train_Exploits_sampled, train_Fuzzers_sampled, train_Generic_sampled,\n",
    "                          train_Reconnaissance_sampled, train_Shellcode_sampled],\n",
    "                         axis=0)\n",
    "trainW_nonself.to_csv(\"test_20/seed/trainW_nonself.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nonself.to_csv(\"train_nonself.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_nonself = pd.DataFrame(scaler.fit_transform(train_nonself).round(5))\n",
    "test_nonself = pd.DataFrame(scaler.fit_transform(test_nonself).round(5))\n",
    "train_self = pd.DataFrame(scaler.fit_transform(train_self).round(5))\n",
    "test_self = pd.DataFrame(scaler.fit_transform(test_self).round(5))\n",
    "\n",
    "test_nonself.to_csv(\"test_nonself.csv\",index=False)\n",
    "train_nonself.to_csv(\"train_nonself.csv\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
      "95744    0.661656   tcp    http   FIN     10     10     804    1330   \n",
      "44163    1.501572   tcp    http   FIN     60     16   68195     698   \n",
      "35746    0.022939   tcp       -   FIN     40     42    2542   23508   \n",
      "13713    0.333839   tcp     ssh   FIN     32     24    3728    5474   \n",
      "32127    0.023857   tcp       -   FIN     50     48    3062   32538   \n",
      "...           ...   ...     ...   ...    ...    ...     ...     ...   \n",
      "108496   0.000000   arp       -   INT      1      0      46       0   \n",
      "40558    0.027629   tcp       -   FIN     40     42    2542   23508   \n",
      "40383    0.494978   tcp    smtp   FIN     52     42   37232    3380   \n",
      "9790     0.180892   tcp       -   FIN     22     24    3952    2768   \n",
      "45909   47.022953   tcp       -   FIN     20     14    5032     622   \n",
      "\n",
      "               rate  sttl  ...  ct_src_dport_ltm  ct_dst_sport_ltm  \\\n",
      "95744     28.715827    62  ...                 2                 1   \n",
      "44163     49.947654   254  ...                 1                 1   \n",
      "35746   3531.104190    31  ...                 1                 1   \n",
      "13713    164.750074    31  ...                 1                 1   \n",
      "32127   4065.892720    31  ...                 1                 1   \n",
      "...             ...   ...  ...               ...               ...   \n",
      "108496     0.000000     0  ...                 2                 2   \n",
      "40558   2931.702281    31  ...                 1                 1   \n",
      "40383    187.887134    31  ...                 1                 1   \n",
      "9790     248.767213    31  ...                 1                 1   \n",
      "45909      0.701785   254  ...                 1                 1   \n",
      "\n",
      "        ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  \\\n",
      "95744                5             0           0                 1   \n",
      "44163                2             0           0                 0   \n",
      "35746                1             0           0                 0   \n",
      "13713                5             0           0                 0   \n",
      "32127                6             0           0                 0   \n",
      "...                ...           ...         ...               ...   \n",
      "108496               2             0           0                 0   \n",
      "40558                1             0           0                 0   \n",
      "40383                2             0           0                 0   \n",
      "9790                 6             0           0                 0   \n",
      "45909                4             0           0                 0   \n",
      "\n",
      "        ct_src_ltm  ct_srv_dst  is_sm_ips_ports  attack_cat  \n",
      "95744            2           5                0      Normal  \n",
      "44163            1           2                0      Normal  \n",
      "35746            6           6                0      Normal  \n",
      "13713            3           1                0      Normal  \n",
      "32127            4           8                0      Normal  \n",
      "...            ...         ...              ...         ...  \n",
      "108496           2           2                1      Normal  \n",
      "40558            6           1                0      Normal  \n",
      "40383            2           2                0      Normal  \n",
      "9790             8           9                0      Normal  \n",
      "45909            1           4                0      Normal  \n",
      "\n",
      "[560 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "fewshot = train_nonself.sample(frac = 0.01, random_state=42)\n",
    "print(fewshot)\n",
    "fewshot.to_csv('fewshot.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_self_20 =  train_self.sample(n=56000, random_state=42)\n",
    "train_self_20.to_csv(\"evaluate/train_self.csv\",index = False)\n",
    "\n",
    "test_self_20 = test_self.sample(n=3000 , random_state=42)\n",
    "test_self_20.to_csv(\"evaluate/test_self.csv\",index=False)\n",
    "\n",
    "test_nonself = pd.read_csv(\"nonself/test_nonself.csv\")\n",
    "test_nonself = test_nonself.sample(n=3000, random_state=42)\n",
    "test_nonself.to_csv(\"evaluate/test_nonself.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
