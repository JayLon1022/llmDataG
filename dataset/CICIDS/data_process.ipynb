{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1353594/2464509963.py:4: DtypeWarning: Columns (0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_2 = pd.read_csv(\"origin/Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\")\n",
      "/tmp/ipykernel_1353594/2464509963.py:6: DtypeWarning: Columns (0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_4 = pd.read_csv(\"origin/Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv\")\n",
      "/tmp/ipykernel_1353594/2464509963.py:10: DtypeWarning: Columns (0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_8 = pd.read_csv(\"origin/Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列数: 80\n"
     ]
    }
   ],
   "source": [
    "# 载入原始数据集\n",
    "import pandas as pd\n",
    "data_1 = pd.read_csv(\"origin/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\")\n",
    "data_2 = pd.read_csv(\"origin/Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\")\n",
    "data_3 = pd.read_csv(\"origin/Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\")\n",
    "data_4 = pd.read_csv(\"origin/Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv\")\n",
    "data_5 = pd.read_csv(\"origin/Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\")\n",
    "data_6 = pd.read_csv(\"origin/Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv\")\n",
    "data_7 = pd.read_csv(\"origin/Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\")\n",
    "data_8 = pd.read_csv(\"origin/Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\")\n",
    "data = pd.concat([data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8])\n",
    "print(\"列数:\", len(data.columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7235679\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Timestamp'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 删除异常数据\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.12/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[1;32m   5582\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   5583\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   5584\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   5585\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   5586\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   5587\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[1;32m   5588\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   5589\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.12/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.12/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.12/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Timestamp'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# 删除异常数据\n",
    "\n",
    "data = data.drop(['Timestamp'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Label'] != 'Label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7235620\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.sample(n=20000, random_state=42)\n",
    "\n",
    "test_data = data[~data.index.isin(train_data.index)].sample(n=20000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "训练集标签分布:\n",
      "\n",
      "各标签数量及占比:\n",
      "Benign: 14939 (74.69%)\n",
      "DDOS attack-HOIC: 1946 (9.73%)\n",
      "DoS attacks-Hulk: 1304 (6.52%)\n",
      "Bot: 834 (4.17%)\n",
      "Infilteration: 440 (2.20%)\n",
      "DoS attacks-SlowHTTPTest: 379 (1.90%)\n",
      "DoS attacks-GoldenEye: 125 (0.62%)\n",
      "DoS attacks-Slowloris: 26 (0.13%)\n",
      "DDOS attack-LOIC-UDP: 4 (0.02%)\n",
      "Brute Force -Web: 2 (0.01%)\n",
      "SQL Injection: 1 (0.01%)\n",
      "\n",
      "测试集标签分布:\n",
      "\n",
      "各标签数量及占比:\n",
      "Benign: 14978 (74.89%)\n",
      "DDOS attack-HOIC: 1927 (9.63%)\n",
      "DoS attacks-Hulk: 1250 (6.25%)\n",
      "Bot: 815 (4.08%)\n",
      "Infilteration: 444 (2.22%)\n",
      "DoS attacks-SlowHTTPTest: 424 (2.12%)\n",
      "DoS attacks-GoldenEye: 128 (0.64%)\n",
      "DoS attacks-Slowloris: 28 (0.14%)\n",
      "DDOS attack-LOIC-UDP: 5 (0.03%)\n",
      "Brute Force -XSS: 1 (0.01%)\n"
     ]
    }
   ],
   "source": [
    "# 打印标签分布\n",
    "print(\"\\n训练集标签分布:\")\n",
    "label_counts = train_data['Label'].value_counts()\n",
    "total = len(train_data)\n",
    "\n",
    "print(\"\\n各标签数量及占比:\")\n",
    "for label, count in label_counts.items():\n",
    "    percentage = count/total * 100\n",
    "    print(f\"{label}: {count} ({percentage:.2f}%)\")\n",
    "    \n",
    "print(\"\\n测试集标签分布:\")\n",
    "label_counts = test_data['Label'].value_counts()\n",
    "total = len(test_data)\n",
    "\n",
    "print(\"\\n各标签数量及占比:\")\n",
    "for label, count in label_counts.items():\n",
    "    percentage = count/total * 100\n",
    "    print(f\"{label}: {count} ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正常流量数量: 5444525\n",
      "DDoS攻击数量: 687742\n",
      "DoS攻击数量: 654300\n",
      "Bot攻击数量: 286191\n",
      "渗透攻击数量: 161934\n",
      "暴力破解攻击数量: 841\n",
      "SQL注入攻击数量: 87\n"
     ]
    }
   ],
   "source": [
    "# 正常流量\n",
    "benign_data = data[data['Label'] == 'Benign']\n",
    "print(\"正常流量数量:\", len(benign_data))\n",
    "\n",
    "# DDoS攻击\n",
    "ddos_hoic_data = data[data['Label'] == 'DDOS attack-HOIC'] \n",
    "ddos_loic_data = data[data['Label'] == 'DDOS attack-LOIC-UDP']\n",
    "ddos = pd.concat([ddos_hoic_data, ddos_loic_data])\n",
    "print(\"DDoS攻击数量:\", len(ddos))\n",
    "\n",
    "# DoS攻击\n",
    "dos_hulk_data = data[data['Label'] == 'DoS attacks-Hulk']\n",
    "dos_slowhttp_data = data[data['Label'] == 'DoS attacks-SlowHTTPTest']\n",
    "dos_golden_data = data[data['Label'] == 'DoS attacks-GoldenEye']\n",
    "dos_slowloris_data = data[data['Label'] == 'DoS attacks-Slowloris']\n",
    "dos = pd.concat([dos_hulk_data, dos_slowhttp_data, dos_golden_data, dos_slowloris_data])\n",
    "print(\"DoS攻击数量:\", len(dos))\n",
    "\n",
    "# Bot攻击\n",
    "bot_data = data[data['Label'] == 'Bot']\n",
    "bot = pd.concat([bot_data])\n",
    "print(\"Bot攻击数量:\", len(bot))\n",
    "\n",
    "# 渗透攻击\n",
    "infilteration_data = data[data['Label'] == 'Infilteration']\n",
    "infilteration = pd.concat([infilteration_data])\n",
    "print(\"渗透攻击数量:\", len(infilteration))\n",
    "\n",
    "# 暴力破解攻击\n",
    "bruteforce_web_data = data[data['Label'] == 'Brute Force -Web']\n",
    "bruteforce_xss_data = data[data['Label'] == 'Brute Force -XSS']\n",
    "bruteforce = pd.concat([bruteforce_web_data, bruteforce_xss_data])\n",
    "print(\"暴力破解攻击数量:\", len(bruteforce))\n",
    "\n",
    "# SQL注入攻击\n",
    "sql_injection_data = data[data['Label'] == 'SQL Injection']\n",
    "sql_injection = pd.concat([sql_injection_data])\n",
    "print(\"SQL注入攻击数量:\", len(sql_injection))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_train = benign_data.sample(n=20000, random_state=42)\n",
    "benign_test = benign_data[~benign_data.index.isin(benign_train.index)].sample(n=100000, random_state=42)\n",
    "\n",
    "ddos_train = ddos.sample(n=500, random_state=42)\n",
    "ddos_test = ddos[~ddos.index.isin(ddos_train.index)].sample(n=10000, random_state=42)\n",
    "\n",
    "dos_train = dos.sample(n=500, random_state=42)\n",
    "dos_test = dos[~dos.index.isin(dos_train.index)].sample(n=10000, random_state=42)\n",
    "\n",
    "bot_train = bot.sample(n=300, random_state=42)\n",
    "bot_test = bot[~bot.index.isin(bot_train.index)].sample(n=10000, random_state=42)\n",
    "\n",
    "infilteration_train = infilteration.sample(n=300, random_state=42)\n",
    "infilteration_test = infilteration[~infilteration.index.isin(infilteration_train.index)].sample(n=10000, random_state=42)\n",
    "\n",
    "bruteforce_train = bruteforce.sample(n=100, random_state=42)\n",
    "bruteforce_test = bruteforce[~bruteforce.index.isin(bruteforce_train.index)].sample(n=700, random_state=42)\n",
    "\n",
    "sql_injection_train = sql_injection.sample(n=20, random_state=42)\n",
    "sql_injection_test = sql_injection[~sql_injection.index.isin(sql_injection_train.index)].sample(n=67, random_state=42)\n",
    "\n",
    "train_data = pd.concat([benign_data, ddos_train, dos_train, bot_train, infilteration_train, bruteforce_train, sql_injection_train])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集测试集\n",
    "train_data = pd.concat([benign_data, dos, ddos, bruteforce, sql_injection])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
