{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c593754589f346b4bbbbcd432b6d3cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import set_seed\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "import re\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "# 检查设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 本地模型llama3 8B\n",
    "model_name = \"Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "# 加载分词器和模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side='left')\n",
    "\n",
    "# 如果 tokenizer 没有 pad_token，设置一个\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "\n",
    "# 未知类型\n",
    "unknown_type = 'F'\n",
    "\n",
    "# 重复次数\n",
    "Round = 7\n",
    "\n",
    "# 自体半径\n",
    "self_radius = 0.005\n",
    "\n",
    "# 条数：1->n\n",
    "some = \"5\"\n",
    "\n",
    "# 变异轮数\n",
    "round = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool\n",
    "\n",
    "# 读取数据\n",
    "def get_data(data_df):\n",
    "    data = data_df.map(str).apply(lambda row: f\"[{' '.join(row)}]\", axis=1).tolist()\n",
    "    return data\n",
    "\n",
    "\n",
    "# 清除对话的函数\n",
    "def reset() -> list:\n",
    "    return []\n",
    "\n",
    "# 调用模型生成对话的函数\n",
    "def generate_new_vector(prompt: str, user_prompt: str, temp=0.7) -> list:\n",
    "    try:\n",
    "        messages = []\n",
    "        # 添加任务提示\n",
    "        messages.append({'role': 'system', 'content': prompt})\n",
    "        \n",
    "        # # 构建历史对话记录\n",
    "        # for input_text, response_text in chatbot[-3:]:\n",
    "        #     messages.append({'role': 'user', 'content': input_text})\n",
    "        #     messages.append({'role': 'assistant', 'content': response_text})\n",
    "\n",
    "        # 添加当前用户输入\n",
    "        messages.append({'role': 'user', 'content': user_prompt})\n",
    "\n",
    "        # 生成输出\n",
    "        outputs = model.generate(\n",
    "            tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device),\n",
    "            max_new_tokens=1024,\n",
    "            temperature=temp,\n",
    "            eos_token_id=[tokenizer.eos_token_id],\n",
    "        )\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "        # 将结果添加到对话历史\n",
    "        # chatbot.append((user_prompt, response))\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"发生错误：{e}\")\n",
    "        response = f\"抱歉，发生了错误：{e}\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "def clean_value(value):\n",
    "    return float(re.sub(r'[\\[\\]]', '', value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(Round):\n",
    "    # 初始自体非自体\n",
    "    \n",
    "    known = pd.read_csv(f'../dataset/seed/{unknown_type}/Round{r+1}/train{unknown_type}_nonself.csv')\n",
    "\n",
    "\n",
    "    known.to_csv(f\"Round{r+1}/detectors_0.csv\",index=False)\n",
    "\n",
    "\n",
    "    for epoch in range(round):\n",
    "        # epoch = 1\n",
    "        dataset = pd.read_csv(f\"Round{r+1}/detectors_{epoch}.csv\")\n",
    "\n",
    "\n",
    "        # 获取数据\n",
    "        data = get_data(dataset)\n",
    "\n",
    "\n",
    "        chatbot_history = reset()\n",
    "\n",
    "        results = []\n",
    "        for i, vector in enumerate(data):\n",
    "            other_indices = random.sample([idx for idx in range(len(data)) if idx != i], 10)\n",
    "            input_dataset = [data[idx] for idx in other_indices] + [data[i]]\n",
    "            \n",
    "            # input_dataset = data[i -10 :i + 10]\n",
    "            system_prompt = f\"You are a professional data analyst with expertise in vector analysis and spatial distribution. Task: You will be given a dataset: {input_dataset}. Analyze the dataset's features and its spatial distribution. Based on the provided input vector, generate new vectors that exhibit similar characteristics but fill in gaps in the feature space of the dataset. Each element of the new vectors must be a five-decimal number within the range (0, 1) and must not have zero as the last decimal place. Ensure that each generated number is meaningful and does not contain redundant zeros or repeating digits. Important: Ensure that the generated vectors represent meaningful variations that reflect the underlying spatial structure of the dataset. Provide only the output vectors, without any explanation or process details. Output Format MUST be: 1.23456, 2.34567, 3.45678, ...Note: Focus on the spatial analysis and ensure that new vectors cover areas of the feature space that are underrepresented or not captured by the current dataset.\"\n",
    "            response = generate_new_vector(system_prompt, f\"Generate exactly {some} new vectors based on the input vector: {vector}\")\n",
    "            # print(f\"Original Vector: {vector}\")\n",
    "            response = response.split('assistant\\n\\n')\n",
    "            response = response[-1]\n",
    "            response = re.sub(r'(?<!\\b0\\.)\\b[1-9]\\d*\\.\\s*|[,\\[\\]]', '', response)\n",
    "            # print(response)\n",
    "            vectors = re.findall(r'(\\b\\d+(?:\\.\\d+)?(?:[eE][+-]?\\d+)?\\b(?:\\s+\\b\\d+(?:\\.\\d+)?(?:[eE][+-]?\\d+)?\\b){41})', response)\n",
    "            \n",
    "            # 筛除异常输出\n",
    "            if(len(vectors)==0):\n",
    "                continue\n",
    "            \n",
    "            # 检验生成质量\n",
    "            check = len(vectors[0].split())\n",
    "            # print(check)\n",
    "            \n",
    "            # 不合格再次请求\n",
    "            while(check!=42):\n",
    "                response = generate_new_vector(system_prompt, f\"Generate exactly {some} new vectors based on the input vector: {vector}\")\n",
    "                response = response.split('assistant\\n\\n')\n",
    "                response = response[-1]\n",
    "                response = re.sub(r'(?<!\\b0\\.)\\b[1-9]\\d*\\.\\s*|[,\\[\\]]', '', response)\n",
    "                vectors = re.findall(r'(\\b\\d+(?:\\.\\d+)?(?:[eE][+-]?\\d+)?\\b(?:\\s+\\b\\d+(?:\\.\\d+)?(?:[eE][+-]?\\d+)?\\b){41})', response)\n",
    "                check = len(vectors[0].split())\n",
    "                # print(check)\n",
    "                \n",
    "\n",
    "            for v in vectors:\n",
    "                result = list(map(float, v.split()))\n",
    "                # print(f\"Mutated Vector: {v}\")\n",
    "                results.append(result)\n",
    "                \n",
    "        df = pd.DataFrame(results, columns=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"40\", \"41\"])\n",
    "        df.to_csv(f\"Round{r+1}/detectors_{epoch+1}.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
