{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "\n",
    "unknown_type = \"W\"\n",
    "path = f\"../results/test/train{unknown_type}/\"\n",
    "\n",
    "\n",
    "train_self = pd.read_csv(f'../dataset/evaluate/train_self.csv')\n",
    "test_self = pd.read_csv(f'../dataset/evaluate/test_self.csv')\n",
    "test_nonself = pd.read_csv(f'../dataset/evaluate/test_nonself.csv')\n",
    "known = pd.read_csv(f\"{path}detectors_0.csv\")\n",
    "# train_set_unknown = pd.read_csv(f'../dataset/check/train/train{unknown_type}.csv')\n",
    "test_set_unknown = pd.read_csv(f'../dataset/check/test/test{unknown_type}.csv')\n",
    "self_radius = 0.14\n",
    "\n",
    "with open(f\"coverage_results_epoch.txt\", \"w\") as f:\n",
    "    f.write(f\"Base:\\n\")\n",
    "    f.write(f\"Unknown type: {unknown_type}\\n\")\n",
    "    f.write(f\"Number of self samples in train_set: {len(train_self)}\\n\")\n",
    "    f.write(f\"Number of known samples: {len(known)}\\n\")\n",
    "    # f.write(f\"Number of unknown samples in train_set: {len(train_set_unknown)}\\n\")\n",
    "    \n",
    "    \n",
    "    f.write(f\"Evaluate:\\n\")\n",
    "    f.write(f\"Number of self samples in test_set: {len(test_self)}\\n\")\n",
    "    f.write(f\"Number of non-self samples in test_set: {len(test_nonself)}\\n\")\n",
    "    f.write(f\"Number of unknown samples in test_set: {len(test_set_unknown)}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 读取数据\n",
    "def get_data(data_df):\n",
    "    data = data_df.map(str).apply(lambda row: f\"[{' '.join(row)}]\", axis=1).tolist()\n",
    "    return data\n",
    "\n",
    "# 添加检测半径\n",
    "def add_detection_radius(detectors_df):\n",
    "    detector_coords = detectors_df.values\n",
    "    self_coords = train_self.values\n",
    "    distances = cdist(detector_coords, self_coords)\n",
    "    detectors_df['radius'] = distances.min(axis=1) - self_radius\n",
    "    detectors_df['radius'] = detectors_df['radius'].clip(lower=0)  # 确保半径非负\n",
    "    return detectors_df\n",
    "\n",
    "\n",
    "# 评估非自体覆盖率\n",
    "def evaluate_nonselfcoverage(detectors_df, nonself_df):\n",
    "    detector_coords = detectors_df.values[:,:-1]\n",
    "    nonself_coords = nonself_df.values\n",
    "    distances = cdist(nonself_coords, detector_coords)\n",
    "    radii = detectors_df['radius'].values.reshape(1, -1)\n",
    "    covered = (distances <= radii).any(axis=1)\n",
    "    covered_count = covered.sum()\n",
    "    \n",
    "    # nonself_df['covered'] = covered\n",
    "    # return nonself_df\n",
    "    return covered_count\n",
    "    \n",
    "# 评估非自体覆盖情况\n",
    "def evaluate_nonself_coverage(detectors_df):\n",
    "    detector_coords = detectors_df.iloc[:, :-1].values\n",
    "    nonself_coords = test_nonself.values\n",
    "    distances = cdist(nonself_coords, detector_coords)\n",
    "    radii = detectors_df['radius'].values.reshape(1, -1)\n",
    "    covered = (distances <= radii).any(axis=1)\n",
    "    return covered  # 返回每个非自体样本是否被覆盖的布尔数组\n",
    "\n",
    "# 评估自体覆盖情况\n",
    "def evaluate_self_coverage(detectors_df):\n",
    "    detector_coords = detectors_df.iloc[:, :-1].values\n",
    "    self_coords = test_self.values\n",
    "    distances = cdist(self_coords, detector_coords)\n",
    "    radii = detectors_df['radius'].values.reshape(1, -1)\n",
    "    covered = (distances <= radii).any(axis=1)\n",
    "    return covered  # 返回每个自体样本是否被覆盖的布尔数组\n",
    "\n",
    "# 计算指标\n",
    "def calculate_metrics(self_covered, nonself_covered, total_self, total_nonself):\n",
    "\n",
    "    TP = nonself_covered.sum()  # 非自体 被正确检测为 异常\n",
    "    FP = self_covered.sum()  # 自体 被错误检测为 异常\n",
    "    FN = total_nonself - TP  # 非自体 被错误检测为 正常 （非自体 没有 被正确检测为 异常 ）\n",
    "    TN = total_self - FP  # 自体 被正确检测为 正常（自体 没有被 错误检测为 异常）\n",
    "\n",
    "    # 计算指标\n",
    "    accuracy = (TP + TN) / (total_self + total_nonself)\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    fpr = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    confusion_matrix = np.array([[TN, FP], [FN, TP]])\n",
    "    \n",
    "    return {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1_score,\n",
    "        \"False Positive Rate (FPR)\": fpr,\n",
    "        \"Confusion Matrix\": confusion_matrix\n",
    "    }\n",
    "\n",
    "\n",
    "# 性能评估\n",
    "def evaluate_detector_performance(epoch, detectors_df):\n",
    "    detectors_df_copy = detectors_df.copy()\n",
    "    detectors_radius = add_detection_radius(detectors_df_copy)\n",
    "    \n",
    "    with open(f\"coverage_results_epoch.txt\", \"a\") as f:\n",
    "        f.write(f\"Epoch: {epoch}\\n\")\n",
    "        f.write(f\"Number of detectors: {len(detectors_df)}\\n\")\n",
    "        # f.write(f\"Number of unknown samples in train_set covered by detectors: {evaluate_nonselfcoverage(detectors_radius,train_set_unknown)}\\n\")\n",
    "        # f.write(f\"Train set unknown covery:{evaluate_nonselfcoverage(detectors_radius,train_set_unknown)/len(test_set_unknown):.4f}\\n\")\n",
    "        # f.write(f\"Number of unknown samples in test_set covered by detectors: {evaluate_nonselfcoverage(detectors_radius,test_set_unknown)}\\n\")\n",
    "        f.write(f\"Unknown covery:{evaluate_nonselfcoverage(detectors_radius,test_set_unknown)/len(test_set_unknown):.4f}\\n\")\n",
    "    # 评估测试集中自体和非自体的覆盖情况\n",
    "    self_covered = evaluate_self_coverage(detectors_radius)\n",
    "    nonself_covered = evaluate_nonself_coverage(detectors_radius)\n",
    "\n",
    "    # 计算各项指标\n",
    "    metrics = calculate_metrics(\n",
    "        self_covered=self_covered,\n",
    "        nonself_covered=nonself_covered,\n",
    "        total_self=len(test_self),\n",
    "        total_nonself=len(test_nonself)\n",
    "    )\n",
    "    with open(f\"coverage_results_epoch.txt\", \"a\") as f:\n",
    "        # f.write('Metrics:\\n')\n",
    "        for metric, value in metrics.items(): \n",
    "                if metric == \"Confusion Matrix\":\n",
    "                    f.write(f\"{metric}:\\n{value}\\n\")\n",
    "                else:\n",
    "                    f.write(f\"{metric}: {value:.4f}\\n\")\n",
    "        f.write('\\n')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "dataset0 = pd.read_csv(f\"{path}detectors_0.csv\")\n",
    "evaluate_detector_performance(0, dataset0)\n",
    "dataset1 = pd.read_csv(f\"{path}detectors_1.csv\")\n",
    "evaluate_detector_performance(1, dataset1)\n",
    "dataset2 = pd.read_csv(f\"{path}detectors_2.csv\")\n",
    "evaluate_detector_performance(2, dataset2)\n",
    "dataset3 = pd.read_csv(f\"{path}detectors_3.csv\")\n",
    "evaluate_detector_performance(3, dataset3)\n",
    "# dataset4 = pd.read_csv(f\"{path}detectors_4.csv\")\n",
    "# evaluate_unknown(4, dataset4)\n",
    "\n",
    "dataset = pd.read_csv(f\"{path}detectors.csv\")\n",
    "evaluate_detector_performance(999, dataset)\n",
    "\n",
    "\n",
    "\n",
    "# dataset = pd.concat([dataset0, dataset1, dataset2, dataset3], ignore_index=True)\n",
    "# dataset = pd.concat([dataset0, dataset1, dataset2, dataset3, dataset4], ignore_index=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
