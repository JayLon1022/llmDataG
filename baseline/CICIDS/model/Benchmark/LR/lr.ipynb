{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理未知类型: bot\n",
      "加载数据...\n",
      "训练集分布：\n",
      "label\n",
      "0    1500\n",
      "1    1420\n",
      "Name: count, dtype: int64\n",
      "\n",
      "测试集分布：\n",
      "label\n",
      "0    5000\n",
      "1    5000\n",
      "Name: count, dtype: int64\n",
      "预处理数据...\n",
      "训练逻辑回归模型...\n",
      "训练完成，耗时: 1.76 秒\n",
      "评估模型...\n",
      "结果已保存到 bot/lr_results.txt\n",
      "处理未知类型: bruteforce\n",
      "加载数据...\n",
      "训练集分布：\n",
      "label\n",
      "1    1620\n",
      "0    1500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "测试集分布：\n",
      "label\n",
      "0    5000\n",
      "1    5000\n",
      "Name: count, dtype: int64\n",
      "预处理数据...\n",
      "训练逻辑回归模型...\n",
      "训练完成，耗时: 2.25 秒\n",
      "评估模型...\n",
      "结果已保存到 bruteforce/lr_results.txt\n",
      "处理未知类型: dos\n",
      "加载数据...\n",
      "训练集分布：\n",
      "label\n",
      "0    1500\n",
      "1    1220\n",
      "Name: count, dtype: int64\n",
      "\n",
      "测试集分布：\n",
      "label\n",
      "0    5000\n",
      "1    5000\n",
      "Name: count, dtype: int64\n",
      "预处理数据...\n",
      "训练逻辑回归模型...\n",
      "训练完成，耗时: 3.46 秒\n",
      "评估模型...\n",
      "结果已保存到 dos/lr_results.txt\n",
      "处理未知类型: ddos\n",
      "加载数据...\n",
      "训练集分布：\n",
      "label\n",
      "0    1500\n",
      "1    1220\n",
      "Name: count, dtype: int64\n",
      "\n",
      "测试集分布：\n",
      "label\n",
      "0    5000\n",
      "1    5000\n",
      "Name: count, dtype: int64\n",
      "预处理数据...\n",
      "训练逻辑回归模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaylon/anaconda3/envs/llm/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练完成，耗时: 2.33 秒\n",
      "评估模型...\n",
      "结果已保存到 ddos/lr_results.txt\n",
      "处理未知类型: infilteration\n",
      "加载数据...\n",
      "训练集分布：\n",
      "label\n",
      "0    1500\n",
      "1    1420\n",
      "Name: count, dtype: int64\n",
      "\n",
      "测试集分布：\n",
      "label\n",
      "0    5000\n",
      "1    5000\n",
      "Name: count, dtype: int64\n",
      "预处理数据...\n",
      "训练逻辑回归模型...\n",
      "训练完成，耗时: 0.14 秒\n",
      "评估模型...\n",
      "结果已保存到 infilteration/lr_results.txt\n",
      "处理未知类型: sql_injection\n",
      "加载数据...\n",
      "训练集分布：\n",
      "label\n",
      "1    1700\n",
      "0    1500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "测试集分布：\n",
      "label\n",
      "0    5000\n",
      "1    5000\n",
      "Name: count, dtype: int64\n",
      "预处理数据...\n",
      "训练逻辑回归模型...\n",
      "训练完成，耗时: 0.06 秒\n",
      "评估模型...\n",
      "结果已保存到 sql_injection/lr_results.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# 设置随机种子以确保结果可复现\n",
    "np.random.seed(42)\n",
    "\n",
    "# 数据加载\n",
    "def load_data(train_self_path, train_nonself_path, test_self_path, test_nonself_path,unknown_path):\n",
    "    \n",
    "    train_self = pd.read_csv(train_self_path)\n",
    "    train_self = train_self.sample(n=1500,random_state=42)\n",
    "    train_nonself = pd.read_csv(train_nonself_path)\n",
    "    \n",
    "    unknown = pd.read_csv(unknown_path)\n",
    "    \n",
    "    # 加载测试数据\n",
    "    test_self = pd.read_csv(test_self_path)\n",
    "    test_self = test_self.sample(n=5000,random_state=42)\n",
    "    test_nonself = pd.read_csv(test_nonself_path)\n",
    "    test_nonself = test_nonself.sample(n=5000,random_state=42)\n",
    "    \n",
    "    # 添加标签：自体为0，非自体为1\n",
    "    train_self['label'] = 0\n",
    "    train_nonself['label'] = 1\n",
    "    test_self['label'] = 0\n",
    "    test_nonself['label'] = 1\n",
    "    \n",
    "    # 合并训练集和测试集\n",
    "    train_data = pd.concat([train_self, train_nonself], axis=0).reset_index(drop=True)\n",
    "    test_data = pd.concat([test_self, test_nonself], axis=0).reset_index(drop=True)\n",
    "    print(\"训练集分布：\")\n",
    "    print(train_data['label'].value_counts())\n",
    "    print(\"\\n测试集分布：\")\n",
    "    print(test_data['label'].value_counts())\n",
    "    return train_data, test_data, unknown\n",
    "\n",
    "# 数据预处理函数\n",
    "def preprocess_data(train_data, test_data):\n",
    "    # 处理缺失值\n",
    "    train_data = train_data.fillna(train_data.mean())\n",
    "    test_data = test_data.fillna(test_data.mean())\n",
    "    # 分离特征和标签\n",
    "    X_train = train_data.drop('label', axis=1).values\n",
    "    y_train = train_data['label'].values\n",
    "    X_test = test_data.drop('label', axis=1).values\n",
    "    y_test = test_data['label'].values\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# 训练逻辑回归模型\n",
    "def train_model(X_train, y_train, C=1.0, max_iter=100):\n",
    "    # 创建逻辑回归分类器\n",
    "    model = LogisticRegression(\n",
    "        C=C,\n",
    "        max_iter=max_iter,\n",
    "        random_state=42,\n",
    "        n_jobs=-1  # 使用所有可用的CPU核心\n",
    "    )\n",
    "    \n",
    "    # 训练模型\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    return model, training_time\n",
    "\n",
    "# 评估未知覆盖率\n",
    "def evaluate_unknown_coverage(model, unknown_data, threshold=0.5):\n",
    "    # 预处理未知数据 - 填充缺失值\n",
    "    unknown_data = unknown_data.fillna(unknown_data.mean())\n",
    "    X_unknown = unknown_data.values\n",
    "    \n",
    "    # 预测概率\n",
    "    y_proba = model.predict_proba(X_unknown)[:, 1]\n",
    "    \n",
    "    # 根据阈值确定预测结果\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    # 计算未知覆盖率 - 被检测为异常的未知样本比例\n",
    "    unknown_coverage = np.mean(y_pred)\n",
    "    \n",
    "    return unknown_coverage\n",
    "\n",
    "# 评估误报率 - 在正常数据上\n",
    "def evaluate_false_positive_rate(model, normal_data, threshold=0.5):\n",
    "    # 预处理正常数据 - 填充缺失值\n",
    "    normal_data = normal_data.fillna(normal_data.mean())\n",
    "    X_normal = normal_data.drop('label', axis=1).values\n",
    "    \n",
    "    # 预测概率\n",
    "    y_proba = model.predict_proba(X_normal)[:, 1]\n",
    "    \n",
    "    # 根据阈值确定预测结果\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    # 计算误报率 - 正常样本被错误分类为异常的比例\n",
    "    false_positive_rate = np.mean(y_pred)\n",
    "    \n",
    "    return false_positive_rate\n",
    "\n",
    "# 评估模型性能\n",
    "def evaluate_model(model, X_test, y_test, threshold=0.5):\n",
    "    # 预测概率\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # 根据阈值确定预测结果\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    # 计算评估指标\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, conf_matrix\n",
    "\n",
    "# 计算最佳阈值\n",
    "def find_optimal_threshold(model, X_val, y_val, unknown_data, normal_data):\n",
    "    # 确保没有 NaN 值\n",
    "    unknown_data = unknown_data.fillna(unknown_data.mean())\n",
    "    normal_data = normal_data.fillna(normal_data.mean())\n",
    "    \n",
    "    if np.isnan(X_val).any():\n",
    "        # 使用简单的均值填充\n",
    "        col_mean = np.nanmean(X_val, axis=0)\n",
    "        # 找到 NaN 的索引\n",
    "        inds = np.where(np.isnan(X_val))\n",
    "        # 用列均值替换 NaN\n",
    "        X_val[inds] = np.take(col_mean, inds[1])\n",
    "    \n",
    "    \n",
    "    # 收集所有预测分数\n",
    "    y_proba = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # 尝试不同阈值\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    results = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        # 计算验证集上的F1分数\n",
    "        y_pred = (y_proba >= threshold).astype(int)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        \n",
    "        # 计算未知覆盖率\n",
    "        unknown_cov = evaluate_unknown_coverage(model, unknown_data, threshold)\n",
    "        \n",
    "        # 计算误报率\n",
    "        fpr = evaluate_false_positive_rate(model, normal_data, threshold)\n",
    "        \n",
    "        # 计算综合得分 (可以根据需要调整权重)\n",
    "        score = f1 * 0.4 + unknown_cov * 0.4 - fpr * 0.2\n",
    "        \n",
    "        results.append((threshold, f1, unknown_cov, fpr, score))\n",
    "    \n",
    "    # 找到最佳阈值\n",
    "    best_result = max(results, key=lambda x: x[4])\n",
    "    return best_result\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    unknown_types = [\"bot\", \"bruteforce\", \"dos\", \"ddos\", \"infilteration\", \"sql_injection\"]\n",
    "    for unknown_type in unknown_types:\n",
    "        # 设置数据路径\n",
    "        train_self_path = '../../../check/self/train_self.csv'\n",
    "        train_nonself_path = f'../../../check/train/unknown_{unknown_type}.csv'\n",
    "        test_self_path = '../../../check/self/test_self.csv'\n",
    "        test_nonself_path = '../../../check/nonself/test_nonself.csv'\n",
    "        unknown_path = f'../../../check/unknown/{unknown_type}.csv'\n",
    "        \n",
    "        # 加载数据\n",
    "        print(f\"处理未知类型: {unknown_type}\")\n",
    "        print(\"加载数据...\")\n",
    "        train_data, test_data, unknown = load_data(train_self_path, train_nonself_path, test_self_path, test_nonself_path,unknown_path)\n",
    "        \n",
    "        # 预处理数据\n",
    "        print(\"预处理数据...\")\n",
    "        X_train, y_train, X_test, y_test = preprocess_data(train_data, test_data)\n",
    "        \n",
    "        # 将训练集分为训练集和验证集（80%训练，20%验证）\n",
    "        train_size = int(0.8 * len(X_train))\n",
    "        X_train_split, X_val = X_train[:train_size], X_train[train_size:]\n",
    "        y_train_split, y_val = y_train[:train_size], y_train[train_size:]\n",
    "        \n",
    "        # 训练模型\n",
    "        print(\"训练逻辑回归模型...\")\n",
    "        model, training_time = train_model(X_train_split, y_train_split, C=1.0, max_iter=1000)\n",
    "        print(f\"训练完成，耗时: {training_time:.2f} 秒\")\n",
    "        \n",
    "        # 评估模型\n",
    "        print(\"评估模型...\")\n",
    "        accuracy, precision, recall, f1, conf_matrix = evaluate_model(model, X_test, y_test)\n",
    "        unknown_coverage = evaluate_unknown_coverage(model, unknown)\n",
    "        test_self_data = test_data[test_data['label'] == 0]\n",
    "        false_positive_rate = evaluate_false_positive_rate(model, test_self_data)\n",
    "        \n",
    "        # 保存结果\n",
    "        results = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'unknown_coverage': unknown_coverage,\n",
    "            'false_positive_rate': false_positive_rate,\n",
    "            'training_time': training_time,\n",
    "            'confusion_matrix': conf_matrix.tolist()\n",
    "        }\n",
    "        \n",
    "        # 创建目录（如果不存在）\n",
    "        import os\n",
    "        if not os.path.exists(unknown_type):\n",
    "            os.makedirs(unknown_type)\n",
    "        \n",
    "        # 将结果保存为文本文件\n",
    "        with open(f'{unknown_type}/lr_results.txt', 'w') as f:\n",
    "            for key, value in results.items():\n",
    "                if key != 'confusion_matrix':\n",
    "                    f.write(f\"{key}: {value}\\n\")\n",
    "            f.write(f\"confusion_matrix:\\n{conf_matrix}\\n\")\n",
    "        \n",
    "        print(f\"结果已保存到 {unknown_type}/lr_results.txt\")\n",
    "\n",
    "        # 计算最佳阈值\n",
    "        validation_data = pd.concat([train_data, test_data], axis=0).sample(frac=0.2, random_state=42)\n",
    "        X_val_data = validation_data.drop('label', axis=1).values\n",
    "        y_val_data = validation_data['label'].values\n",
    "        best_result = find_optimal_threshold(model, X_val_data, y_val_data, unknown, test_self_data)\n",
    "        best_threshold, best_f1, best_unknown_cov, best_fpr, best_score = best_result\n",
    "        \n",
    "        with open(f'{unknown_type}/best_threshold_results.txt', 'w') as f:\n",
    "            f.write(f\"Best Threshold: {best_threshold:.6f}\\n\")\n",
    "            f.write(f\"F1 Score at Best Threshold: {best_f1:.4f}\\n\")\n",
    "            f.write(f\"Unknown Coverage at Best Threshold: {best_unknown_cov:.4f}\\n\")\n",
    "            f.write(f\"False Positive Rate at Best Threshold: {best_fpr:.4f}\\n\")\n",
    "            f.write(f\"Combined Score: {best_score:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
