{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unknown_type = \"A\"\n",
    "unknown_types = [\"A\", \"B\", \"D\", \"E\", \"F\", \"G\", \"R\", \"S\", \"W\"]\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义V-detector\n",
    "class VDetector:\n",
    "    def __init__(self, self_radius, coverage_threshold=0.999, max_detectors=50000):\n",
    "        self.self_radius = self_radius\n",
    "        self.coverage_threshold = coverage_threshold\n",
    "        self.max_detectors = max_detectors\n",
    "        self.detectors = []\n",
    "        \n",
    "    def _calculate_detector_radius(self, candidate, self_samples):\n",
    "        distances = cdist([candidate], self_samples)[0]\n",
    "        return np.min(distances) - self.self_radius\n",
    "    \n",
    "    def _is_covered_by_detectors(self, point, detectors):\n",
    "        if not detectors:\n",
    "            return False\n",
    "        \n",
    "        centers = np.array([d[0] for d in detectors])\n",
    "        radii = np.array([d[1] for d in detectors])\n",
    "        \n",
    "        distances = cdist([point], centers)[0]\n",
    "        return np.any(distances <= radii)\n",
    "    \n",
    "    def generate_detectors(self, self_samples, output_dir):\n",
    "    # 确保目录存在\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            \n",
    "        self_samples = np.array(self_samples)\n",
    "        batch_size = 5000  \n",
    "        attempts = 0\n",
    "        max_attempts = self.max_detectors * 100\n",
    "        \n",
    "        start_time = time.time()\n",
    "        pbar = tqdm(total=self.max_detectors, desc=f\"generating detectors (r={self.self_radius})\")\n",
    "        \n",
    "        while len(self.detectors) < self.max_detectors and attempts < max_attempts:\n",
    "            # 批量生成候选点\n",
    "            candidates = np.random.uniform(0, 1, size=(batch_size, self_samples.shape[1]))\n",
    "            \n",
    "            for candidate in candidates:\n",
    "                radius = self._calculate_detector_radius(candidate, self_samples)\n",
    "                \n",
    "                if radius > 0 and not self._is_covered_by_detectors(candidate, self.detectors):\n",
    "                    self.detectors.append((candidate, radius))\n",
    "                    pbar.update(1)\n",
    "\n",
    "                    # 每生成100个检测器检查一次覆盖率\n",
    "                    if len(self.detectors) % 100 == 0:\n",
    "                        coverage = self._estimate_coverage()\n",
    "                        pbar.set_postfix({\"coverage\": f\"{coverage:.2%}\"})\n",
    "                        \n",
    "                        if coverage >= self.coverage_threshold:\n",
    "                            break\n",
    "                        \n",
    "            attempts += batch_size\n",
    "        \n",
    "            \n",
    "            if len(self.detectors) >= self.max_detectors or self._estimate_coverage() >= self.coverage_threshold:\n",
    "                break\n",
    "        \n",
    "        pbar.close()\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        final_coverage = self._estimate_coverage()\n",
    "        \n",
    "        print(f\"Generated {len(self.detectors)} detectors after {attempts} attempts\")\n",
    "        print(f\"Final coverage: {final_coverage:.2%}\")\n",
    "        \n",
    "        # 将检测器保存为CSV文件\n",
    "        centers = np.array([d[0] for d in self.detectors])\n",
    "        radii = np.array([d[1] for d in self.detectors])\n",
    "        \n",
    "        # 创建包含中心点和半径的DataFrame\n",
    "        detector_df = pd.DataFrame(centers)\n",
    "        detector_df.columns = [f'center_{i}' for i in range(centers.shape[1])]\n",
    "        detector_df['radius'] = radii\n",
    "        \n",
    "        # 保存为CSV文件 - 使用os.path.join确保路径正确\n",
    "        csv_path = os.path.join(output_dir, f'detectors_r{self.self_radius}.csv')\n",
    "        detector_df.to_csv(csv_path, index=False)\n",
    "        print(f\"Detectors saved to {csv_path}\")\n",
    "        \n",
    "        return final_coverage\n",
    "        \n",
    "    def _estimate_coverage(self, sample_size=420000):\n",
    "        if not self.detectors:\n",
    "            return 0.0\n",
    "\n",
    "        samples = np.random.uniform(0, 1, size=(sample_size, len(self.detectors[0][0])))\n",
    "      \n",
    "        covered = sum(self._is_covered_by_detectors(s, self.detectors) for s in samples)\n",
    "        return covered / sample_size\n",
    "    \n",
    "    def predict(self, samples):\n",
    "        samples = np.array(samples)\n",
    "        results = np.zeros(len(samples), dtype=bool)\n",
    "        \n",
    "        for i, sample in enumerate(samples):\n",
    "            results[i] = self._is_covered_by_detectors(sample, self.detectors)\n",
    "            \n",
    "        return results\n",
    "\n",
    "# 评价指标\n",
    "def evaluate_performance(self_predictions, nonself_predictions, unknown_predictions, test_self, test_nonself, unknown, output_dir, self_radius):\n",
    "    TP = np.sum(nonself_predictions)  \n",
    "    FP = np.sum(self_predictions)     \n",
    "    FN = len(test_nonself) - TP       \n",
    "    TN = len(test_self) - FP  \n",
    "    \n",
    "    metrics = {\n",
    "        \"Accuracy\": (TP + TN) / (len(test_self) + len(test_nonself)),\n",
    "        \"Precision\": TP / (TP + FP) if (TP + FP) > 0 else 0,\n",
    "        \"Recall\": TP / (TP + FN) if (TP + FN) > 0 else 0,\n",
    "        \"False Positive Rate\": FP / (FP + TN) if (FP + TN) > 0 else 0,\n",
    "        \"Unknown Coverage Rate\": np.sum(unknown_predictions) / len(unknown),\n",
    "        \"Confusion Matrix\": np.array([[TP, FP], [FN, TN]])\n",
    "    }\n",
    "    \n",
    "    if metrics[\"Precision\"] + metrics[\"Recall\"] > 0:\n",
    "        metrics[\"F1 Score\"] = 2 * (metrics[\"Precision\"] * metrics[\"Recall\"]) / (metrics[\"Precision\"] + metrics[\"Recall\"])\n",
    "    else:\n",
    "        metrics[\"F1 Score\"] = 0\n",
    "    \n",
    "    # 使用os.path.join确保路径正确    \n",
    "    results_path = os.path.join(output_dir, \"results.txt\")\n",
    "    with open(results_path, \"w\") as f:\n",
    "        f.write(\"Performance Metrics:\\n\")\n",
    "        f.write(f\"Number of test self samples: {len(test_self)}\\n\")\n",
    "        f.write(f\"Number of test non-self samples: {len(test_nonself)}\\n\")\n",
    "        f.write(f\"Number of unknown samples: {len(unknown)}\\n\\n\")\n",
    "        \n",
    "        for metric, value in metrics.items():\n",
    "            if metric == \"Confusion Matrix\":\n",
    "                f.write(f\"{metric}:\\n{value}\\n\")\n",
    "            else:\n",
    "                f.write(f\"{metric}: {value:.2%}\\n\")\n",
    "    \n",
    "    plot_metrics = {k: v for k, v in metrics.items() if k != \"Confusion Matrix\"}\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(plot_metrics.keys(), plot_metrics.values())\n",
    "    plt.title(f'V-detector Performance Metrics (r={self_radius})')\n",
    "    plt.ylabel('Value')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2%}',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    chart_path = os.path.join(output_dir, \"metrics_bar_chart.png\")\n",
    "    plt.savefig(chart_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加自体数量消融实验函数\n",
    "# 修复ablation_study_self_count函数中的plot_self_count_ablation调用\n",
    "def ablation_study_self_count(self_radius, self_counts, unknown_type):\n",
    "    \"\"\"\n",
    "    对自体样本数量进行消融实验\n",
    "    \n",
    "    参数:\n",
    "    self_radius: 固定的自体半径\n",
    "    self_counts: 要测试的自体样本数量列表\n",
    "    unknown_type: 未知类型\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    print(f\"加载数据集: {unknown_type}\")\n",
    "    train_nonself = pd.read_csv(f\"../../check/train/trainset_{unknown_type}_nonself.csv\")\n",
    "    train_self_full = pd.read_csv(\"../../check/self/train_self_new.csv\").sample(frac=1, random_state=42)\n",
    "\n",
    "    test_self = pd.read_csv(\"../../check/self/test_self_new.csv\")\n",
    "    test_self = test_self.sample(n=5000, random_state=42)\n",
    "\n",
    "    test_nonself = pd.read_csv(\"../../check/nonself/test_nonself.csv\")\n",
    "    test_nonself = test_nonself.sample(n=5000, random_state=42)\n",
    "\n",
    "    train_set_unknown = pd.read_csv(f'../../check/unknown/train/train{unknown_type}.csv')\n",
    "    test_set_unknown = pd.read_csv(f'../../check/unknown/test/test{unknown_type}.csv')\n",
    "    unknown = pd.concat([train_set_unknown, test_set_unknown])\n",
    "    \n",
    "    all_metrics = {}\n",
    "\n",
    "    # 创建保存目录\n",
    "    base_dir = f'{unknown_type}/self_count_ablation'\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "\n",
    "    with open(f\"{base_dir}/ablation_results.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"自体样本数量消融实验 (未知类型: {unknown_type}, 自体半径: {self_radius})\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "    \n",
    "    for count in self_counts:\n",
    "        print(f\"\\n测试自体样本数量: {count}\")\n",
    "        # 为每个数量创建单独的目录\n",
    "        count_dir = f\"{base_dir}/count_{count}\"\n",
    "        if not os.path.exists(count_dir):\n",
    "            os.makedirs(count_dir)\n",
    "        \n",
    "        # 从完整训练集中采样指定数量的自体样本\n",
    "        train_self = train_self_full.sample(n=min(count, len(train_self_full)), random_state=42)\n",
    "        \n",
    "        # 初始化和训练检测器\n",
    "        detector = VDetector(self_radius=self_radius)\n",
    "        detector.generate_detectors(train_self, count_dir)\n",
    "\n",
    "        # 预测\n",
    "        self_predictions = detector.predict(test_self)\n",
    "        nonself_predictions = detector.predict(test_nonself)\n",
    "        unknown_predictions = detector.predict(unknown)\n",
    "        \n",
    "        # 评估性能\n",
    "        metrics = evaluate_performance(self_predictions, nonself_predictions, unknown_predictions, \n",
    "                                      test_self, test_nonself, unknown, \n",
    "                                      count_dir, self_radius)\n",
    "        \n",
    "        # 保存结果\n",
    "        all_metrics[count] = metrics\n",
    "        \n",
    "        # 将结果追加到消融实验文件\n",
    "        with open(f\"{base_dir}/ablation_results.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"\\n自体样本数量: {count}\\n\")\n",
    "            for metric, value in metrics.items():\n",
    "                if metric == \"Confusion Matrix\":\n",
    "                    f.write(f\"{metric}:\\n{value}\\n\")\n",
    "                else:\n",
    "                    f.write(f\"{metric}: {value:.2%}\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "    \n",
    "    # 绘制消融实验结果 - 修复这里，传入base_dir参数\n",
    "    plot_self_count_ablation(all_metrics, unknown_type, self_radius, base_dir)\n",
    "    \n",
    "    # 找出最佳自体样本数量\n",
    "    best_count = find_best_self_count(all_metrics)\n",
    "    \n",
    "    with open(f\"{base_dir}/best_count.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"最佳自体样本数量: {best_count}\\n\")\n",
    "        f.write(f\"自体半径: {self_radius}\\n\")\n",
    "        f.write(\"最佳指标:\\n\")\n",
    "        for metric, value in all_metrics[best_count].items():\n",
    "            if metric == \"Confusion Matrix\":\n",
    "                f.write(f\"{metric}:\\n{value}\\n\")\n",
    "            else:\n",
    "                f.write(f\"{metric}: {value:.2%}\\n\")\n",
    "    \n",
    "    return all_metrics, best_count\n",
    "\n",
    "def plot_self_count_ablation(all_metrics, unknown_type, self_radius, base_dir):\n",
    "\n",
    "    \"\"\"绘制自体样本数量消融实验结果\"\"\"\n",
    "    metrics_to_plot = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"False Positive Rate\", \"Unknown Coverage Rate\"]\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for metric in metrics_to_plot:\n",
    "        counts = sorted(list(all_metrics.keys()))\n",
    "        values = [all_metrics[c][metric] for c in counts]\n",
    "        \n",
    "        plt.plot(counts, values, marker='o', label=metric)\n",
    "    \n",
    "    plt.xlabel('自体样本数量')\n",
    "    plt.ylabel('指标值')\n",
    "    plt.title(f'V-Detector 自体样本数量消融实验 (类型: {unknown_type}, 自体半径: {self_radius})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{base_dir}/ablation_results.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def find_best_self_count(all_metrics):\n",
    "    \"\"\"找出最佳自体样本数量\"\"\"\n",
    "    best_score = -1\n",
    "    best_count = None\n",
    "    \n",
    "    for count, metrics in all_metrics.items():\n",
    "        # 使用F1分数和未知覆盖率的加权和作为评分标准\n",
    "        score = 0.7 * metrics[\"F1 Score\"] + 0.3 * metrics[\"Unknown Coverage Rate\"]\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_count = count\n",
    "    \n",
    "    return best_count\n",
    "\n",
    "# 双参数消融实验\n",
    "def dual_ablation_study(self_radii, self_counts, unknown_type):\n",
    "    \"\"\"\n",
    "    同时对自体半径和自体样本数量进行消融实验\n",
    "    \n",
    "    参数:\n",
    "    self_radii: 要测试的自体半径列表\n",
    "    self_counts: 要测试的自体样本数量列表\n",
    "    unknown_type: 未知类型\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    print(f\"加载数据集: {unknown_type}\")\n",
    "    train_nonself = pd.read_csv(f\"../../check/train/trainset_{unknown_type}_nonself.csv\")\n",
    "    train_self_full = pd.read_csv(\"../../check/self/train_self_new.csv\").sample(frac=1, random_state=42)\n",
    "\n",
    "    test_self = pd.read_csv(\"../../check/self/test_self_new.csv\")\n",
    "    test_self = test_self.sample(n=5000, random_state=42)\n",
    "\n",
    "    test_nonself = pd.read_csv(\"../../check/nonself/test_nonself.csv\")\n",
    "    test_nonself = test_nonself.sample(n=5000, random_state=42)\n",
    "\n",
    "    train_set_unknown = pd.read_csv(f'../../check/unknown/train/train{unknown_type}.csv')\n",
    "    test_set_unknown = pd.read_csv(f'../../check/unknown/test/test{unknown_type}.csv')\n",
    "    unknown = pd.concat([train_set_unknown, test_set_unknown])\n",
    "    \n",
    "    # 创建保存目录\n",
    "    if not os.path.exists(f'{unknown_type}/dual_ablation'):\n",
    "        os.makedirs(f'{unknown_type}/dual_ablation')\n",
    "    \n",
    "    # 记录所有参数组合的结果\n",
    "    all_results = {}\n",
    "    \n",
    "    with open(f\"{unknown_type}/dual_ablation/results.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"自体半径和样本数量双参数消融实验 (未知类型: {unknown_type})\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\")\n",
    "    \n",
    "    # 创建结果矩阵用于热力图\n",
    "    f1_scores = np.zeros((len(self_radii), len(self_counts)))\n",
    "    unknown_coverage = np.zeros((len(self_radii), len(self_counts)))\n",
    "    combined_scores = np.zeros((len(self_radii), len(self_counts)))\n",
    "    \n",
    "    for i, radius in enumerate(self_radii):\n",
    "        all_results[radius] = {}\n",
    "        \n",
    "        for j, count in enumerate(self_counts):\n",
    "            print(f\"\\n测试参数组合: 自体半径={radius}, 自体样本数量={count}\")\n",
    "            \n",
    "            # 从完整训练集中采样指定数量的自体样本\n",
    "            train_self = train_self_full.sample(n=min(count, len(train_self_full)), random_state=42)\n",
    "            \n",
    "            # 初始化和训练检测器\n",
    "            detector = VDetector(self_radius=radius)\n",
    "            detector.generate_detectors(train_self, f\"{unknown_type}/dual_ablation/r{radius}_c{count}\")\n",
    "\n",
    "            # 预测\n",
    "            self_predictions = detector.predict(test_self)\n",
    "            nonself_predictions = detector.predict(test_nonself)\n",
    "            unknown_predictions = detector.predict(unknown)\n",
    "            \n",
    "            # 评估性能\n",
    "            metrics = evaluate_performance(self_predictions, nonself_predictions, unknown_predictions, \n",
    "                                          test_self, test_nonself, unknown, \n",
    "                                          f\"{unknown_type}/dual_ablation/r{radius}_c{count}\", radius)\n",
    "            \n",
    "            # 保存结果\n",
    "            all_results[radius][count] = metrics\n",
    "            \n",
    "            # 更新结果矩阵\n",
    "            f1_scores[i, j] = metrics[\"F1 Score\"]\n",
    "            unknown_coverage[i, j] = metrics[\"Unknown Coverage Rate\"]\n",
    "            combined_scores[i, j] = 0.7 * metrics[\"F1 Score\"] + 0.3 * metrics[\"Unknown Coverage Rate\"]\n",
    "            \n",
    "            # 将结果追加到文件\n",
    "            with open(f\"{unknown_type}/dual_ablation/results.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"\\n自体半径: {radius}, 自体样本数量: {count}\\n\")\n",
    "                for metric, value in metrics.items():\n",
    "                    if metric == \"Confusion Matrix\":\n",
    "                        f.write(f\"{metric}:\\n{value}\\n\")\n",
    "                    else:\n",
    "                        f.write(f\"{metric}: {value:.2%}\\n\")\n",
    "                f.write(\"-\" * 60 + \"\\n\")\n",
    "    \n",
    "    # 绘制热力图\n",
    "    plot_heatmaps(self_radii, self_counts, f1_scores, unknown_coverage, combined_scores, unknown_type)\n",
    "    \n",
    "    # 找出最佳参数组合\n",
    "    best_radius, best_count = find_best_parameters(combined_scores, self_radii, self_counts)\n",
    "    \n",
    "    with open(f\"{unknown_type}/dual_ablation/best_parameters.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"最佳参数组合:\\n\")\n",
    "        f.write(f\"自体半径: {best_radius}\\n\")\n",
    "        f.write(f\"自体样本数量: {best_count}\\n\")\n",
    "        f.write(\"\\n最佳指标:\\n\")\n",
    "        for metric, value in all_results[best_radius][best_count].items():\n",
    "            if metric == \"Confusion Matrix\":\n",
    "                f.write(f\"{metric}:\\n{value}\\n\")\n",
    "            else:\n",
    "                f.write(f\"{metric}: {value:.2%}\\n\")\n",
    "    \n",
    "    return all_results, best_radius, best_count\n",
    "\n",
    "def plot_heatmaps(self_radii, self_counts, f1_scores, unknown_coverage, combined_scores, unknown_type):\n",
    "    \"\"\"绘制热力图展示双参数消融实验结果\"\"\"\n",
    "    # 创建图形\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # F1分数热力图\n",
    "    im0 = axes[0].imshow(f1_scores, cmap='viridis', interpolation='nearest')\n",
    "    axes[0].set_title('F1 Score')\n",
    "    axes[0].set_xlabel('自体样本数量')\n",
    "    axes[0].set_ylabel('自体半径')\n",
    "    axes[0].set_xticks(np.arange(len(self_counts)))\n",
    "    axes[0].set_yticks(np.arange(len(self_radii)))\n",
    "    axes[0].set_xticklabels(self_counts)\n",
    "    axes[0].set_yticklabels(self_radii)\n",
    "    plt.colorbar(im0, ax=axes[0])\n",
    "    \n",
    "    # 未知覆盖率热力图\n",
    "    im1 = axes[1].imshow(unknown_coverage, cmap='viridis', interpolation='nearest')\n",
    "    axes[1].set_title('Unknown Coverage Rate')\n",
    "    axes[1].set_xlabel('自体样本数量')\n",
    "    axes[1].set_ylabel('自体半径')\n",
    "    axes[1].set_xticks(np.arange(len(self_counts)))\n",
    "    axes[1].set_yticks(np.arange(len(self_radii)))\n",
    "    axes[1].set_xticklabels(self_counts)\n",
    "    axes[1].set_yticklabels(self_radii)\n",
    "    plt.colorbar(im1, ax=axes[1])\n",
    "    \n",
    "    # 综合得分热力图\n",
    "    im2 = axes[2].imshow(combined_scores, cmap='viridis', interpolation='nearest')\n",
    "    axes[2].set_title('Combined Score (0.7*F1 + 0.3*Coverage)')\n",
    "    axes[2].set_xlabel('自体样本数量')\n",
    "    axes[2].set_ylabel('自体半径')\n",
    "    axes[2].set_xticks(np.arange(len(self_counts)))\n",
    "    axes[2].set_yticks(np.arange(len(self_radii)))\n",
    "    axes[2].set_xticklabels(self_counts)\n",
    "    axes[2].set_yticklabels(self_radii)\n",
    "    plt.colorbar(im2, ax=axes[2])\n",
    "    \n",
    "    # 添加数值标签\n",
    "    for i in range(len(self_radii)):\n",
    "        for j in range(len(self_counts)):\n",
    "            axes[0].text(j, i, f\"{f1_scores[i, j]:.2f}\", ha=\"center\", va=\"center\", color=\"w\" if f1_scores[i, j] < 0.7 else \"black\")\n",
    "            axes[1].text(j, i, f\"{unknown_coverage[i, j]:.2f}\", ha=\"center\", va=\"center\", color=\"w\" if unknown_coverage[i, j] < 0.7 else \"black\")\n",
    "            axes[2].text(j, i, f\"{combined_scores[i, j]:.2f}\", ha=\"center\", va=\"center\", color=\"w\" if combined_scores[i, j] < 0.7 else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{unknown_type}/dual_ablation/heatmaps.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def find_best_parameters(combined_scores, self_radii, self_counts):\n",
    "    \"\"\"找出最佳参数组合\"\"\"\n",
    "    max_idx = np.unravel_index(np.argmax(combined_scores), combined_scores.shape)\n",
    "    best_radius = self_radii[max_idx[0]]\n",
    "    best_count = self_counts[max_idx[1]]\n",
    "    return best_radius, best_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始处理未知类型: A\n",
      "\n",
      "使用初始自体半径 0.05 执行自体数量消融实验...\n",
      "加载数据集: A\n",
      "\n",
      "测试自体样本数量: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating detectors (r=0.05):   0%|          | 1/50000 [00:05<77:22:51,  5.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1 detectors after 5000 attempts\n",
      "Final coverage: 99.98%\n",
      "Detectors saved to A/self_count_ablation/count_50/detectors_r0.05.csv\n",
      "\n",
      "测试自体样本数量: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating detectors (r=0.05):   0%|          | 3/50000 [00:06<28:20:44,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3 detectors after 5000 attempts\n",
      "Final coverage: 100.00%\n",
      "Detectors saved to A/self_count_ablation/count_100/detectors_r0.05.csv\n",
      "\n",
      "测试自体样本数量: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating detectors (r=0.05):   0%|          | 3/50000 [00:06<28:18:59,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3 detectors after 5000 attempts\n",
      "Final coverage: 100.00%\n",
      "Detectors saved to A/self_count_ablation/count_200/detectors_r0.05.csv\n",
      "\n",
      "测试自体样本数量: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating detectors (r=0.05):   0%|          | 2/50000 [00:06<42:12:09,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2 detectors after 5000 attempts\n",
      "Final coverage: 100.00%\n",
      "Detectors saved to A/self_count_ablation/count_500/detectors_r0.05.csv\n",
      "\n",
      "测试自体样本数量: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating detectors (r=0.05):   0%|          | 2/50000 [00:06<42:17:19,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2 detectors after 5000 attempts\n",
      "Final coverage: 100.00%\n",
      "Detectors saved to A/self_count_ablation/count_1000/detectors_r0.05.csv\n",
      "\n",
      "测试自体样本数量: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating detectors (r=0.05):   0%|          | 2/50000 [00:06<44:25:13,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2 detectors after 5000 attempts\n",
      "Final coverage: 100.00%\n",
      "Detectors saved to A/self_count_ablation/count_2000/detectors_r0.05.csv\n",
      "\n",
      "测试自体样本数量: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating detectors (r=0.05):   0%|          | 4/50000 [00:07<26:14:48,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4 detectors after 5000 attempts\n",
      "Final coverage: 99.99%\n",
      "Detectors saved to A/self_count_ablation/count_5000/detectors_r0.05.csv\n",
      "\n",
      "测试自体样本数量: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating detectors (r=0.05):   0%|          | 2/50000 [00:07<55:12:37,  3.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2 detectors after 5000 attempts\n",
      "Final coverage: 99.98%\n",
      "Detectors saved to A/self_count_ablation/count_10000/detectors_r0.05.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1412747/3501293011.py:112: UserWarning: Glyph 33258 (\\N{CJK UNIFIED IDEOGRAPH-81EA}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1412747/3501293011.py:112: UserWarning: Glyph 20307 (\\N{CJK UNIFIED IDEOGRAPH-4F53}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1412747/3501293011.py:112: UserWarning: Glyph 26679 (\\N{CJK UNIFIED IDEOGRAPH-6837}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1412747/3501293011.py:112: UserWarning: Glyph 26412 (\\N{CJK UNIFIED IDEOGRAPH-672C}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1412747/3501293011.py:112: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1412747/3501293011.py:112: UserWarning: Glyph 37327 (\\N{CJK UNIFIED IDEOGRAPH-91CF}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1412747/3501293011.py:112: UserWarning: Glyph 25351 (\\N{CJK UNIFIED IDEOGRAPH-6307}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1412747/3501293011.py:112: UserWarning: Glyph 26631 (\\N{CJK UNIFIED IDEOGRAPH-6807}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1412747/3501293011.py:112: UserWarning: Glyph 20540 (\\N{CJK UNIFIED IDEOGRAPH-503C}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1412747/3501293011.py:112: UserWarning: Glyph 28040 (\\N{CJK UNIFIED IDEOGRAPH-6D88}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1412747/3501293011.py:112: UserWarning: Glyph 34701 (\\N{CJK UNIFIED IDEOGRAPH-878D}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1412747/3501293011.py:112: UserWarning: Glyph 23454 (\\N{CJK UNIFIED IDEOGRAPH-5B9E}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1412747/3501293011.py:112: UserWarning: Glyph 39564 (\\N{CJK UNIFIED IDEOGRAPH-9A8C}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1412747/3501293011.py:112: UserWarning: Glyph 31867 (\\N{CJK UNIFIED IDEOGRAPH-7C7B}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1412747/3501293011.py:112: UserWarning: Glyph 22411 (\\N{CJK UNIFIED IDEOGRAPH-578B}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1412747/3501293011.py:112: UserWarning: Glyph 21322 (\\N{CJK UNIFIED IDEOGRAPH-534A}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1412747/3501293011.py:112: UserWarning: Glyph 24452 (\\N{CJK UNIFIED IDEOGRAPH-5F84}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1412747/3501293011.py:113: UserWarning: Glyph 25351 (\\N{CJK UNIFIED IDEOGRAPH-6307}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f'{base_dir}/ablation_results.png', dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_1412747/3501293011.py:113: UserWarning: Glyph 26631 (\\N{CJK UNIFIED IDEOGRAPH-6807}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f'{base_dir}/ablation_results.png', dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_1412747/3501293011.py:113: UserWarning: Glyph 20540 (\\N{CJK UNIFIED IDEOGRAPH-503C}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f'{base_dir}/ablation_results.png', dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_1412747/3501293011.py:113: UserWarning: Glyph 33258 (\\N{CJK UNIFIED IDEOGRAPH-81EA}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f'{base_dir}/ablation_results.png', dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_1412747/3501293011.py:113: UserWarning: Glyph 20307 (\\N{CJK UNIFIED IDEOGRAPH-4F53}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f'{base_dir}/ablation_results.png', dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_1412747/3501293011.py:113: UserWarning: Glyph 26679 (\\N{CJK UNIFIED IDEOGRAPH-6837}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f'{base_dir}/ablation_results.png', dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_1412747/3501293011.py:113: UserWarning: Glyph 26412 (\\N{CJK UNIFIED IDEOGRAPH-672C}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f'{base_dir}/ablation_results.png', dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_1412747/3501293011.py:113: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f'{base_dir}/ablation_results.png', dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_1412747/3501293011.py:113: UserWarning: Glyph 37327 (\\N{CJK UNIFIED IDEOGRAPH-91CF}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f'{base_dir}/ablation_results.png', dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_1412747/3501293011.py:113: UserWarning: Glyph 28040 (\\N{CJK UNIFIED IDEOGRAPH-6D88}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f'{base_dir}/ablation_results.png', dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_1412747/3501293011.py:113: UserWarning: Glyph 34701 (\\N{CJK UNIFIED IDEOGRAPH-878D}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f'{base_dir}/ablation_results.png', dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_1412747/3501293011.py:113: UserWarning: Glyph 23454 (\\N{CJK UNIFIED IDEOGRAPH-5B9E}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f'{base_dir}/ablation_results.png', dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_1412747/3501293011.py:113: UserWarning: Glyph 39564 (\\N{CJK UNIFIED IDEOGRAPH-9A8C}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f'{base_dir}/ablation_results.png', dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_1412747/3501293011.py:113: UserWarning: Glyph 31867 (\\N{CJK UNIFIED IDEOGRAPH-7C7B}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f'{base_dir}/ablation_results.png', dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_1412747/3501293011.py:113: UserWarning: Glyph 22411 (\\N{CJK UNIFIED IDEOGRAPH-578B}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f'{base_dir}/ablation_results.png', dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_1412747/3501293011.py:113: UserWarning: Glyph 21322 (\\N{CJK UNIFIED IDEOGRAPH-534A}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f'{base_dir}/ablation_results.png', dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_1412747/3501293011.py:113: UserWarning: Glyph 24452 (\\N{CJK UNIFIED IDEOGRAPH-5F84}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(f'{base_dir}/ablation_results.png', dpi=300, bbox_inches='tight')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "找到最佳自体数量: 1000\n",
      "\n",
      "使用最佳自体数量 1000 执行自体半径消融实验...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ablation_study_self_count() got an unexpected keyword argument 'self_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 2. 使用最佳自体数量进行自体半径消融实验\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m使用最佳自体数量 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 执行自体半径消融实验...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m radius_metrics, best_radius \u001b[38;5;241m=\u001b[39m ablation_study_self_count(self_radii, unknown_type, self_count\u001b[38;5;241m=\u001b[39mbest_count)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m找到最佳自体半径: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_radius\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 3. 可选：使用找到的最佳参数再次验证\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: ablation_study_self_count() got an unexpected keyword argument 'self_count'"
     ]
    }
   ],
   "source": [
    "\n",
    "self_radii = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]\n",
    "self_counts = [50, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "\n",
    "\n",
    "for unknown_type in unknown_types:\n",
    "    print(f\"\\n开始处理未知类型: {unknown_type}\")\n",
    "        \n",
    "    # 1. 首先进行自体数量消融实验（使用中等自体半径）\n",
    "    initial_radius = 0.05  # 使用中等自体半径作为初始值\n",
    "    print(f\"\\n使用初始自体半径 {initial_radius} 执行自体数量消融实验...\")\n",
    "    count_metrics, best_count = ablation_study_self_count(initial_radius, self_counts, unknown_type)\n",
    "    print(f\"\\n找到最佳自体数量: {best_count}\")\n",
    "    \n",
    "    # 2. 使用最佳自体数量进行自体半径消融实验\n",
    "    print(f\"\\n使用最佳自体数量 {best_count} 执行自体半径消融实验...\")\n",
    "    radius_metrics, best_radius = ablation_study(self_radii, unknown_type, self_count=best_count)\n",
    "    print(f\"\\n找到最佳自体半径: {best_radius}\")\n",
    "    \n",
    "    # 3. 可选：使用找到的最佳参数再次验证\n",
    "    print(f\"\\n使用最佳参数组合进行最终验证 (半径={best_radius}, 数量={best_count})...\")\n",
    "    \n",
    "    # 加载数据\n",
    "    train_nonself = pd.read_csv(f\"../../check/train/trainset_{unknown_type}_nonself.csv\")\n",
    "    train_self_full = pd.read_csv(\"../../check/self/train_self_new.csv\").sample(frac=1, random_state=42)\n",
    "    train_self = train_self_full.sample(n=min(best_count, len(train_self_full)), random_state=42)\n",
    "\n",
    "    test_self = pd.read_csv(\"../../check/self/test_self_new.csv\")\n",
    "    test_self = test_self.sample(n=5000, random_state=42)\n",
    "\n",
    "    test_nonself = pd.read_csv(\"../../check/nonself/test_nonself.csv\")\n",
    "    test_nonself = test_nonself.sample(n=5000, random_state=42)\n",
    "\n",
    "    train_set_unknown = pd.read_csv(f'../../check/unknown/train/train{unknown_type}.csv')\n",
    "    test_set_unknown = pd.read_csv(f'../../check/unknown/test/test{unknown_type}.csv')\n",
    "    unknown = pd.concat([train_set_unknown, test_set_unknown])\n",
    "    \n",
    "    # 使用最佳参数训练最终模型\n",
    "    final_detector = VDetector(self_radius=best_radius)\n",
    "    final_detector.generate_detectors(train_self, f\"{unknown_type}/final_model\")\n",
    "\n",
    "    # 预测\n",
    "    self_predictions = final_detector.predict(test_self)\n",
    "    nonself_predictions = final_detector.predict(test_nonself)\n",
    "    unknown_predictions = final_detector.predict(unknown)\n",
    "    \n",
    "    # 评估最终性能\n",
    "    final_metrics = evaluate_performance(self_predictions, nonself_predictions, unknown_predictions, \n",
    "                                        test_self, test_nonself, unknown, \n",
    "                                        f\"{unknown_type}/final_model\", best_radius)\n",
    "    \n",
    "    print(f\"\\n未知类型 {unknown_type} 的最终最佳参数:\")\n",
    "    print(f\"自体半径: {best_radius}\")\n",
    "    print(f\"自体样本数量: {best_count}\")\n",
    "    print(f\"最佳F1分数: {final_metrics['F1 Score']:.2%}\")\n",
    "    print(f\"最佳未知覆盖率: {final_metrics['Unknown Coverage Rate']:.2%}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
