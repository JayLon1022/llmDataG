{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理未知类型: A\n",
      "当前自样本数量: 20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 424\u001b[0m\n\u001b[1;32m    421\u001b[0m             f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown Coverage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 424\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[3], line 408\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    371\u001b[0m X_train, y_train, X_test, y_test, X_unknown, y_unknown \u001b[38;5;241m=\u001b[39m preprocess_data(train_data, test_data, unknown)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# # 在所有操作前应用特征选择\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# selected_features = dp_sumic_feature_selection(X_train, y_train, k=5)\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# X_train_selected = X_train[:, selected_features]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# save_results(unknown_type, metrics, unknown_detection_rate)\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;66;03m# print(\"-\" * 50)\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m results_df \u001b[38;5;241m=\u001b[39m parameter_experiment(X_train, y_train, X_test, y_test, X_unknown, y_unknown,unknown_type)\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# 找到最佳参数组合\u001b[39;00m\n\u001b[1;32m    411\u001b[0m best_result \u001b[38;5;241m=\u001b[39m results_df\u001b[38;5;241m.\u001b[39mloc[results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39midxmax()]\n",
      "Cell \u001b[0;32mIn[3], line 326\u001b[0m, in \u001b[0;36mparameter_experiment\u001b[0;34m(X_train, y_train, X_test, y_test, X_unknown, y_unknown, unknown_type)\u001b[0m\n\u001b[1;32m    323\u001b[0m X_nonself \u001b[38;5;241m=\u001b[39m X_train_selected[y_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# print(\"生成边界探测器...\")\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m boundary_detectors \u001b[38;5;241m=\u001b[39m hdbd_boundary_detectors(X_self, grid_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# print(\"使用MDGWO-NSA生成非边界探测器...\")\u001b[39;00m\n\u001b[1;32m    329\u001b[0m mdgwo \u001b[38;5;241m=\u001b[39m MDGWO_NSA(X_self, n_detectors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 128\u001b[0m, in \u001b[0;36mhdbd_boundary_detectors\u001b[0;34m(X_self, grid_size, max_features)\u001b[0m\n\u001b[1;32m    126\u001b[0m idx \u001b[38;5;241m=\u001b[39m it\u001b[38;5;241m.\u001b[39mmulti_index\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grid_space[idx] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 128\u001b[0m     neighbors \u001b[38;5;241m=\u001b[39m get_neighbors(idx, grid_shape)\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(grid_space[n] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m neighbors \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m ni \u001b[38;5;241m<\u001b[39m grid_shape[i] \u001b[38;5;28;01mfor\u001b[39;00m i, ni \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(n))):\n\u001b[1;32m    130\u001b[0m         center_reduced \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([grid_bounds[i] \u001b[38;5;241m+\u001b[39m grid_size \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx])\n",
      "Cell \u001b[0;32mIn[3], line 144\u001b[0m, in \u001b[0;36mget_neighbors\u001b[0;34m(idx, shape)\u001b[0m\n\u001b[1;32m    142\u001b[0m         new_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(idx)\n\u001b[1;32m    143\u001b[0m         new_idx[dim] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m offset\n\u001b[0;32m--> 144\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m new_idx[i] \u001b[38;5;241m<\u001b[39m shape[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(shape))):\n\u001b[1;32m    145\u001b[0m             neighbors\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mtuple\u001b[39m(new_idx))\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m neighbors\n",
      "Cell \u001b[0;32mIn[3], line 144\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    142\u001b[0m         new_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(idx)\n\u001b[1;32m    143\u001b[0m         new_idx[dim] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m offset\n\u001b[0;32m--> 144\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m new_idx[i] \u001b[38;5;241m<\u001b[39m shape[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(shape))):\n\u001b[1;32m    145\u001b[0m             neighbors\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mtuple\u001b[39m(new_idx))\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m neighbors\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mutual_info_score, confusion_matrix\n",
    "from scipy.spatial.distance import euclidean, cdist\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "SELF_RADIUS = 0.05\n",
    "SELF_COUNT = 1000\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn.metrics.cluster._supervised')\n",
    "\n",
    "# 数据加载\n",
    "def load_data(train_self_path, train_nonself_path, test_self_path, test_nonself_path, test_unknown_path, train_unknown_path):\n",
    "    try:\n",
    "        train_self = pd.read_csv(train_self_path).sample(n=SELF_COUNT, random_state=42)\n",
    "        train_nonself = pd.read_csv(train_nonself_path)\n",
    "        test_unknown = pd.read_csv(test_unknown_path)\n",
    "        train_unknown = pd.read_csv(train_unknown_path)\n",
    "        unknown = pd.concat([test_unknown, train_unknown], axis=0).reset_index(drop=True)\n",
    "        test_self = pd.read_csv(test_self_path).sample(n=5000, random_state=42)\n",
    "        test_nonself = pd.read_csv(test_nonself_path).sample(n=5000, random_state=42)\n",
    "\n",
    "        train_self['label'] = 0\n",
    "        train_nonself['label'] = 1\n",
    "        test_self['label'] = 0\n",
    "        test_nonself['label'] = 1\n",
    "        unknown['label'] = 1\n",
    "\n",
    "        train_data = pd.concat([train_self, train_nonself], axis=0).reset_index(drop=True)\n",
    "        test_data = pd.concat([test_self, test_nonself], axis=0).reset_index(drop=True)\n",
    "        return train_data, test_data, unknown\n",
    "    except Exception as e:\n",
    "        print(f\"数据加载失败: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# 数据预处理\n",
    "def preprocess_data(train_data, test_data, unknown):\n",
    "    train_data = train_data.fillna(train_data.mean(numeric_only=True))\n",
    "    test_data = test_data.fillna(test_data.mean(numeric_only=True))\n",
    "    unknown = unknown.fillna(unknown.mean(numeric_only=True))\n",
    "\n",
    "    X_train = train_data.drop('label', axis=1).values\n",
    "    y_train = train_data['label'].values\n",
    "    X_test = test_data.drop('label', axis=1).values\n",
    "    y_test = test_data['label'].values\n",
    "    X_unknown = unknown.drop('label', axis=1).values\n",
    "    y_unknown = unknown['label'].values\n",
    "    return X_train, y_train, X_test, y_test, X_unknown, y_unknown\n",
    "\n",
    "# 特征选择：DP-SUMIC\n",
    "def dp_sumic_feature_selection(X, y, k=5, threshold_mic=0.8):\n",
    "    n_features = X.shape[1]\n",
    "    # 1. 特征聚类\n",
    "    distances = cdist(X.T, X.T)\n",
    "    rho = local_density(distances, k)\n",
    "    delta = np.zeros(n_features)\n",
    "    for i in range(n_features):\n",
    "        higher_density = rho > rho[i]\n",
    "        delta[i] = np.min(distances[i, higher_density]) if higher_density.any() else np.max(distances[i])\n",
    "\n",
    "    D = (rho / np.max(rho)) * (delta / np.max(delta))\n",
    "    cluster_centers = np.argsort(-D)[:int(n_features * 0.3)]\n",
    "\n",
    "    # 2. 类内 SU 和 类间 MIC\n",
    "    su_scores = symmetric_uncertainty(X, y)\n",
    "    mic_scores = np.corrcoef(X.T)\n",
    "    redundant_features = set()\n",
    "    for i in range(n_features):\n",
    "        for j in range(i + 1, n_features):\n",
    "            if mic_scores[i, j] > threshold_mic and su_scores[i] < su_scores[j]:\n",
    "                redundant_features.add(i)\n",
    "    \n",
    "    selected_features = [i for i in range(n_features) if i not in redundant_features]\n",
    "    return selected_features\n",
    "\n",
    "def symmetric_uncertainty(X, y):\n",
    "    su_scores = []\n",
    "    for i in range(X.shape[1]):\n",
    "        mi = mutual_info_score(X[:, i], y)\n",
    "        h_x = entropy(X[:, i])\n",
    "        h_y = entropy(y)\n",
    "        su = 2 * mi / (h_x + h_y) if (h_x + h_y) > 0 else 0\n",
    "        su_scores.append(su)\n",
    "    return np.array(su_scores)\n",
    "\n",
    "def entropy(data):\n",
    "    hist, _ = np.histogram(data, bins=10, density=True)\n",
    "    hist = hist[hist > 0]\n",
    "    return -np.sum(hist * np.log2(hist)) if hist.size > 0 else 0\n",
    "\n",
    "def local_density(distances, k):\n",
    "    n_features = distances.shape[0]\n",
    "    rho = np.zeros(n_features)\n",
    "    for i in range(n_features):\n",
    "        sorted_dist = np.sort(distances[i])\n",
    "        rho[i] = np.sum(np.exp(-sorted_dist[1:k+1]))\n",
    "    return rho\n",
    "\n",
    "# 边界检测器生成\n",
    "def hdbd_boundary_detectors(X_self, grid_size=0.05, max_features=5):\n",
    "    X_self = np.array(X_self)\n",
    "    # 降维到 max_features（不超过 5）\n",
    "    if X_self.shape[1] > max_features:\n",
    "        pca = PCA(n_components=max_features)\n",
    "        X_self_reduced = pca.fit_transform(X_self)\n",
    "    else:\n",
    "        X_self_reduced = X_self\n",
    "    n_features = X_self_reduced.shape[1]\n",
    "\n",
    "    grid_bounds = np.linspace(0, 1, int(1 / grid_size) + 1)\n",
    "    grid_shape = [int(1 / grid_size)] * n_features\n",
    "    grid_space = np.zeros(grid_shape, dtype=int)\n",
    "\n",
    "    for sample in X_self_reduced:\n",
    "        grid_idx = tuple(np.minimum(np.maximum(np.floor(sample / grid_size).astype(int), 0), np.array(grid_shape) - 1))\n",
    "        grid_space[grid_idx] += 1\n",
    "\n",
    "    boundary_detectors = []\n",
    "    it = np.nditer(grid_space, flags=['multi_index'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        if grid_space[idx] == 0:\n",
    "            neighbors = get_neighbors(idx, grid_shape)\n",
    "            if any(grid_space[n] > 0 for n in neighbors if all(0 <= ni < grid_shape[i] for i, ni in enumerate(n))):\n",
    "                center_reduced = np.array([grid_bounds[i] + grid_size / 2 for i in idx])\n",
    "                # 还原到原始维度\n",
    "                center_full = pca.inverse_transform(center_reduced.reshape(1, -1)).flatten()\n",
    "                distance = min([euclidean(center_full, X_self[i]) for i in range(len(X_self))])\n",
    "                boundary_detectors.append((center_full, distance))\n",
    "        it.iternext()\n",
    "    return boundary_detectors\n",
    "\n",
    "def get_neighbors(idx, shape):\n",
    "    neighbors = []\n",
    "    for dim in range(len(idx)):\n",
    "        for offset in [-1, 1]:\n",
    "            new_idx = list(idx)\n",
    "            new_idx[dim] += offset\n",
    "            if all(0 <= new_idx[i] < shape[i] for i in range(len(shape))):\n",
    "                neighbors.append(tuple(new_idx))\n",
    "    return neighbors\n",
    "\n",
    "# 非边界探测器生成（MDGWO-NSA）\n",
    "class MDGWO_NSA:\n",
    "    def __init__(self, X_self, n_detectors=50, max_iter=100, min_radius=0.01, max_radius=0.5):\n",
    "        self.X_self = np.array(X_self)\n",
    "        self.n_detectors = n_detectors\n",
    "        self.max_iter = max_iter\n",
    "        self.dim = X_self.shape[1]\n",
    "        self.min_radius = min_radius\n",
    "        self.max_radius = max_radius\n",
    "\n",
    "    def cluster_self(self):\n",
    "        n_clusters = min(3, len(self.X_self))\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        kmeans.fit(self.X_self)\n",
    "        centers = kmeans.cluster_centers_\n",
    "        labels = kmeans.labels_\n",
    "        radii = []\n",
    "        for i in range(n_clusters):\n",
    "            cluster_points = self.X_self[labels == i]\n",
    "            if len(cluster_points) > 0:\n",
    "                distances = cdist(centers[i:i+1], cluster_points)\n",
    "                radii.append(np.max(distances))\n",
    "            else:\n",
    "                radii.append(self.min_radius)\n",
    "        return centers, np.array(radii)\n",
    "\n",
    "    def fitness(self, detectors, centers, radii):\n",
    "        overlap = 0\n",
    "        coverage = 0\n",
    "        for i, (center, radius) in enumerate(detectors):\n",
    "            # 减小重叠惩罚，增加覆盖奖励\n",
    "            for j in range(i + 1, len(detectors)):\n",
    "                dist = euclidean(detectors[i][0], detectors[j][0])\n",
    "                if dist < detectors[i][1] + detectors[j][1]:\n",
    "                    overlap += (detectors[i][1] + detectors[j][1] - dist) * 0.5\n",
    "\n",
    "            # 自样本覆盖惩罚保持不变\n",
    "            for x in self.X_self:\n",
    "                if euclidean(center, x) < radius:\n",
    "                    overlap += 2.0\n",
    "\n",
    "            # 增加覆盖奖励\n",
    "            coverage += radius ** 2 * 1.5 \n",
    "\n",
    "        return coverage - overlap\n",
    "    def optimize(self):\n",
    "        centers, radii = self.cluster_self()\n",
    "        wolves = np.random.rand(self.n_detectors, self.dim)\n",
    "        wolf_radii = np.random.uniform(self.min_radius, self.max_radius, self.n_detectors)\n",
    "\n",
    "        alpha, beta, delta = wolves[0], wolves[0], wolves[0]\n",
    "        alpha_score, beta_score, delta_score = -np.inf, -np.inf, -np.inf\n",
    "\n",
    "        for t in range(self.max_iter):\n",
    "            a = 2 * (1 - t / self.max_iter)\n",
    "            for i in range(self.n_detectors):\n",
    "                detectors = [(wolves[j], wolf_radii[j]) for j in range(self.n_detectors)]\n",
    "                score = self.fitness(detectors, centers, radii)\n",
    "\n",
    "                if score > alpha_score:\n",
    "                    alpha_score, alpha = score, wolves[i].copy()\n",
    "                elif score > beta_score:\n",
    "                    beta_score, beta = score, wolves[i].copy()\n",
    "                elif score > delta_score:\n",
    "                    delta_score, delta = score, wolves[i].copy()\n",
    "\n",
    "                r1, r2 = np.random.rand(2)\n",
    "                A = 2 * a * r1 - a\n",
    "                C = 2 * r2\n",
    "\n",
    "                D_alpha = abs(C * alpha - wolves[i])\n",
    "                D_beta = abs(C * beta - wolves[i])\n",
    "                D_delta = abs(C * delta - wolves[i])\n",
    "\n",
    "                X1 = alpha - A * D_alpha\n",
    "                X2 = beta - A * D_beta\n",
    "                X3 = delta - A * D_delta\n",
    "\n",
    "                wolves[i] = np.clip((X1 + X2 + X3) / 3, 0, 1)\n",
    "                min_dist_to_self = np.min(cdist(wolves[i].reshape(1, -1), self.X_self))\n",
    "                wolf_radii[i] = np.clip(min_dist_to_self / 2, self.min_radius, self.max_radius)\n",
    "\n",
    "        return [(wolves[i], wolf_radii[i]) for i in range(self.n_detectors)]\n",
    "\n",
    "# 孔洞修复\n",
    "def hole_repair(detectors, X_nonself, threshold_density=0.2, r_min=0.01, r_max=0.1):\n",
    "    repaired_detectors = detectors.copy()\n",
    "    detector_centers = np.array([d[0] for d in detectors])\n",
    "    detector_radii = np.array([d[1] for d in detectors])\n",
    "\n",
    "    # 计算密度\n",
    "    densities = []\n",
    "    for i, (center, radius) in enumerate(detectors):\n",
    "        dist_to_nonself = cdist(center.reshape(1, -1), X_nonself)\n",
    "        density = np.sum(dist_to_nonself < radius) / len(X_nonself)\n",
    "        densities.append(density)\n",
    "\n",
    "    # Rp1: 在低密度区域添加新探测器\n",
    "    for i, density in enumerate(densities):\n",
    "        if density < threshold_density:\n",
    "            new_center = detector_centers[i] + np.random.uniform(-0.1, 0.1, size=detector_centers[i].shape)\n",
    "            new_center = np.clip(new_center, 0, 1)\n",
    "            min_dist_to_self = np.min(cdist(new_center.reshape(1, -1), X_nonself))\n",
    "            new_radius = np.clip(min_dist_to_self / 2, r_min, r_max)\n",
    "            repaired_detectors.append((new_center, new_radius))\n",
    "\n",
    "    return repaired_detectors\n",
    "\n",
    "# 检测函数\n",
    "def detect(test_data, detectors):\n",
    "    predictions = []\n",
    "    for sample in test_data:\n",
    "        is_anomaly = any(euclidean(sample, d[0]) < d[1] for d in detectors)\n",
    "        predictions.append(1 if is_anomaly else 0)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# 评估函数\n",
    "def evaluate(y_true, y_pred, y_unknown, u_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    far = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    uc = np.mean(u_pred == 1)\n",
    "    return acc, precision, recall, f1, far, uc\n",
    "\n",
    "# 保存结果\n",
    "def save_results(unknown_type, metrics, unknown_detection_rate, output_dir=\"results\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    result = {\n",
    "        \"unknown_type\": unknown_type,\n",
    "        \"accuracy\": metrics[0],\n",
    "        \"precision\": metrics[1],\n",
    "        \"recall\": metrics[2],\n",
    "        \"f1_score\": metrics[3],\n",
    "        \"false_alarm_rate\": metrics[4],\n",
    "        \"unknown_detection_rate\": unknown_detection_rate,\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    with open(f\"{output_dir}/results_{unknown_type}.json\", \"w\") as f:\n",
    "        json.dump(result, f, indent=4)\n",
    "    print(f\"结果已保存到 {output_dir}/results_{unknown_type}.json\")\n",
    "\n",
    "# 参数实验\n",
    "def parameter_experiment(X_train, y_train, X_test, y_test, X_unknown, y_unknown,unknown_type):\n",
    "    # 实验参数范围\n",
    "    self_count_range = np.arange(20, 200, 20)\n",
    "    \n",
    "    # 存储结果\n",
    "    results = {\n",
    "        'self_count': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': [],\n",
    "        'far': [],\n",
    "        'uc': []\n",
    "    }\n",
    "    \n",
    "\n",
    "    for count in self_count_range:\n",
    "        # 更新全局参数\n",
    "        global SELF_COUNT\n",
    "        SELF_COUNT = count\n",
    "        print(f\"当前自样本数量: {count}\")\n",
    "        # 在所有操作前应用特征选择\n",
    "        selected_features = dp_sumic_feature_selection(X_train, y_train, k=5)\n",
    "        X_train_selected = X_train[:, selected_features]\n",
    "        X_test_selected = X_test[:, selected_features]\n",
    "        X_unknown_selected = X_unknown[:, selected_features]\n",
    "        \n",
    "        X_self = X_train_selected[y_train == 0]\n",
    "        X_self = pd.DataFrame(X_self).sample(n=count, random_state=42).values\n",
    "        \n",
    "        X_nonself = X_train_selected[y_train == 1]\n",
    "\n",
    "        # print(\"生成边界探测器...\")\n",
    "        boundary_detectors = hdbd_boundary_detectors(X_self, grid_size=0.05, max_features=5)\n",
    "\n",
    "        # print(\"使用MDGWO-NSA生成非边界探测器...\")\n",
    "        mdgwo = MDGWO_NSA(X_self, n_detectors=20, max_iter=50)\n",
    "        nonboundary_detectors = mdgwo.optimize()\n",
    "\n",
    "        # print(\"执行孔洞修复...\")\n",
    "        all_detectors = boundary_detectors + nonboundary_detectors\n",
    "        repaired_detectors = hole_repair(all_detectors, X_nonself)\n",
    "        # print(f\"修复后的探测器数量: {len(repaired_detectors)}\")\n",
    "\n",
    "        # print(\"评估模型性能...\")\n",
    "        y_pred_test = detect(X_test_selected, repaired_detectors)\n",
    "        u_pred = detect(X_unknown_selected, repaired_detectors)\n",
    "\n",
    "        accuracy, precision, recall, f1, fpr, uc = evaluate(y_test, y_pred_test, y_unknown, u_pred)\n",
    "        # print(f\"准确率: {accuracy:.4f}, 精确率: {precision:.4f}, 召回率: {recall:.4f}, F1分数: {f1:.4f}, 误报率: {fpr:.4f}\")\n",
    "\n",
    "        # 存储结果\n",
    "        results['self_count'].append(count)\n",
    "        results['accuracy'].append(accuracy)\n",
    "        results['precision'].append(precision)\n",
    "        results['recall'].append(recall)\n",
    "        results['f1'].append(f1)\n",
    "        results['far'].append(fpr)\n",
    "        results['uc'].append(uc)\n",
    "            \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    unknown_types = [\"A\",'B', \"D\", \"E\", \"F\", \"G\", \"R\", \"S\", \"W\"]\n",
    "    for unknown_type in unknown_types:\n",
    "        print(f\"\\n处理未知类型: {unknown_type}\")\n",
    "        train_self_path = '../../check/self/train_self_new.csv'\n",
    "        train_nonself_path = f'../../check/train/trainset_{unknown_type}_nonself.csv'\n",
    "        test_self_path = '../../check/self/test_self_new.csv'\n",
    "        test_nonself_path = '../../check/nonself/test_nonself.csv'\n",
    "        test_unknown_path = f'../../check/unknown/test/test{unknown_type}.csv'\n",
    "        train_unknown_path = f'../../check/unknown/train/train{unknown_type}.csv'\n",
    "\n",
    "        train_data, test_data, unknown = load_data(train_self_path, train_nonself_path, test_self_path, test_nonself_path, test_unknown_path, train_unknown_path)\n",
    "        if train_data is None:\n",
    "            continue\n",
    "\n",
    "        X_train, y_train, X_test, y_test, X_unknown, y_unknown = preprocess_data(train_data, test_data, unknown)\n",
    "        \n",
    "        # # 在所有操作前应用特征选择\n",
    "        # selected_features = dp_sumic_feature_selection(X_train, y_train, k=5)\n",
    "        # X_train_selected = X_train[:, selected_features]\n",
    "        # X_test_selected = X_test[:, selected_features]\n",
    "        # X_unknown_selected = X_unknown[:, selected_features]\n",
    "\n",
    "        # X_self = X_train_selected[y_train == 0]\n",
    "        # X_nonself = X_train_selected[y_train == 1]\n",
    "\n",
    "        # print(\"生成边界探测器...\")\n",
    "        # boundary_detectors = hdbd_boundary_detectors(X_self, grid_size=0.05, max_features=5)\n",
    "\n",
    "        # print(\"使用MDGWO-NSA生成非边界探测器...\")\n",
    "        # mdgwo = MDGWO_NSA(X_self, n_detectors=20, max_iter=50)\n",
    "        # nonboundary_detectors = mdgwo.optimize()\n",
    "\n",
    "        # print(\"执行孔洞修复...\")\n",
    "        # all_detectors = boundary_detectors + nonboundary_detectors\n",
    "        # repaired_detectors = hole_repair(all_detectors, X_nonself)\n",
    "        # print(f\"修复后的探测器数量: {len(repaired_detectors)}\")\n",
    "\n",
    "        # print(\"评估模型性能...\")\n",
    "        # y_pred_test = detect(X_test_selected, repaired_detectors)\n",
    "        # u_pred = detect(X_unknown_selected, repaired_detectors)\n",
    "\n",
    "        # accuracy, precision, recall, f1, fpr, uc = evaluate(y_test, y_pred_test, y_unknown, u_pred)\n",
    "        # print(f\"准确率: {accuracy:.4f}, 精确率: {precision:.4f}, 召回率: {recall:.4f}, F1分数: {f1:.4f}, 误报率: {fpr:.4f}\")\n",
    "\n",
    "        # unknown_detection_rate = np.mean(u_pred)\n",
    "        # print(f\"未知样本检测率: {unknown_detection_rate:.4f}\")\n",
    "\n",
    "        # metrics = (accuracy, precision, recall, f1, fpr)\n",
    "        # save_results(unknown_type, metrics, unknown_detection_rate)\n",
    "        # print(\"-\" * 50)\n",
    "        \n",
    "        results_df = parameter_experiment(X_train, y_train, X_test, y_test, X_unknown, y_unknown,unknown_type)\n",
    "        \n",
    "        # 找到最佳参数组合\n",
    "        best_result = results_df.loc[results_df['f1'].idxmax()]\n",
    "        # 保存结果\n",
    "        with open(f\"DGA-PSO_{unknown_type}_best_params.txt\", 'w') as f:\n",
    "            f.write(f\"Best Parameters:\\n\")\n",
    "            f.write(f\"Self Count: {int(best_result['self_count'])}\\n\")\n",
    "            f.write(f\"Accuracy: {best_result['accuracy']:.2%}\\n\")\n",
    "            f.write(f\"Precision: {best_result['precision']:.2%}\\n\")\n",
    "            f.write(f\"Recall: {best_result['recall']:.2%}\\n\")\n",
    "            f.write(f\"F1 Score: {best_result['f1']:.2%}\\n\")\n",
    "            f.write(f\"False Alarm Rate: {best_result['far']:.2%}\\n\")\n",
    "            f.write(f\"Unknown Coverage: {best_result['uc']:.2%}\\n\")\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
